\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    
    \usepackage{iftex}
    \ifPDFTeX
    	\usepackage[T1]{fontenc}
    	\usepackage{mathpazo}
    \else
    	\usepackage{fontspec}
    \fi

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range
    \makeatletter % fix for old versions of grffile with XeLaTeX
    \@ifpackagelater{grffile}{2019/11/01}
    {
      % Do nothing on new versions
    }
    {
      \def\Gread@@xetex#1{%
        \IfFileExists{"\Gin@base".bb}%
        {\Gread@eps{\Gin@base.bb}}%
        {\Gread@@xetex@aux#1}%
      }
    }
    \makeatother
    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % common color for the border for error outputs.
    \definecolor{outerrorbackground}{HTML}{FFDFDF}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{C2W3\_Assignment}
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\@namedef{PY@tok@w}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\@namedef{PY@tok@c}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\@namedef{PY@tok@cp}{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\@namedef{PY@tok@k}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kt}{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\@namedef{PY@tok@o}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ow}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@nb}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nf}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@ne}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\@namedef{PY@tok@nv}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@no}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\@namedef{PY@tok@nl}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\@namedef{PY@tok@ni}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\@namedef{PY@tok@na}{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\@namedef{PY@tok@nt}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nd}{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@s}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sd}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@si}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\@namedef{PY@tok@se}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\@namedef{PY@tok@sr}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\@namedef{PY@tok@ss}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sx}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@m}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@gh}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@gu}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\@namedef{PY@tok@gd}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\@namedef{PY@tok@gi}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\@namedef{PY@tok@gr}{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\@namedef{PY@tok@ge}{\let\PY@it=\textit}
\@namedef{PY@tok@gs}{\let\PY@bf=\textbf}
\@namedef{PY@tok@gp}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@go}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\@namedef{PY@tok@gt}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\@namedef{PY@tok@err}{\def\PY@bc##1{{\setlength{\fboxsep}{\string -\fboxrule}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}}
\@namedef{PY@tok@kc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kd}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kr}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@bp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@fm}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@vc}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vg}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vi}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vm}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sa}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sb}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sc}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@dl}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s2}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sh}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s1}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@mb}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mf}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mh}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mi}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@il}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mo}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ch}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\@namedef{PY@tok@cm}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\@namedef{PY@tok@cpf}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\@namedef{PY@tok@c1}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\@namedef{PY@tok@cs}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb. 
    \makeatletter
        \newbox\Wrappedcontinuationbox 
        \newbox\Wrappedvisiblespacebox 
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}} 
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}} 
        \newcommand*\Wrappedcontinuationindent {3ex } 
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox} 
        % Take advantage of the already applied Pygments mark-up to insert 
        % potential linebreaks for TeX processing. 
        %        {, <, #, %, $, ' and ": go to next line. 
        %        _, }, ^, &, >, - and ~: stay at end of broken line. 
        % Use of \textquotesingle for straight quote. 
        \newcommand*\Wrappedbreaksatspecials {% 
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}% 
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}% 
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}% 
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}% 
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}% 
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}% 
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}% 
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}% 
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}% 
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}% 
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}% 
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}% 
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}% 
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}% 
        } 
        % Some characters . , ; ? ! / are not pygmentized. 
        % This macro makes them "active" and they will insert potential linebreaks 
        \newcommand*\Wrappedbreaksatpunct {% 
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}% 
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}% 
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}% 
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}% 
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}% 
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}% 
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}% 
            \catcode`\.\active
            \catcode`\,\active 
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active 
            \lccode`\~`\~ 	
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%
        
        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active 	
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}
    
    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        {\ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \hypertarget{week-3-assignment-data-pipeline-components-for-production-ml}{%
\section{Week 3 Assignment: Data Pipeline Components for Production
ML}\label{week-3-assignment-data-pipeline-components-for-production-ml}}

In this last graded programming exercise of the course, you will put
together all the lessons we've covered so far to handle the first three
steps of a production machine learning project - Data ingestion, Data
Validation, and Data Transformation.

Specifically, you will build the production data pipeline by:

\begin{itemize}
\tightlist
\item
  Performing feature selection
\item
  Ingesting the dataset
\item
  Generating the statistics of the dataset
\item
  Creating a schema as per the domain knowledge
\item
  Creating schema environments
\item
  Visualizing the dataset anomalies
\item
  Preprocessing, transforming and engineering your features
\item
  Tracking the provenance of your data pipeline using ML Metadata
\end{itemize}

Most of these will look familiar already so try your best to do the
exercises by recall or browsing the documentation. If you get stuck
however, you can review the lessons in class and the ungraded labs.

Let's begin!

    \hypertarget{table-of-contents}{%
\subsection{Table of Contents}\label{table-of-contents}}

\begin{itemize}
\tightlist
\item
  \hyperref[1]{1 - Imports}
\item
  \hyperref[2]{2 - Load the Dataset}
\item
  \hyperref[4]{3 - Feature Selection}

  \begin{itemize}
  \tightlist
  \item
    \hyperref[ex-1]{Exercise 1 - Feature Selection}
  \end{itemize}
\item
  \hyperref[4]{4 - Data Pipeline}

  \begin{itemize}
  \tightlist
  \item
    \hyperref[4-1]{4.1 - Setup the Interactive Context}
  \item
    \hyperref[4-2]{4.2 - Generating Examples}

    \begin{itemize}
    \tightlist
    \item
      \hyperref[ex-2]{Exercise 2 - ExampleGen}
    \end{itemize}
  \item
    \hyperref[4-3]{4.3 - Computing Statistics}

    \begin{itemize}
    \tightlist
    \item
      \hyperref[ex-3]{Exercise 3 - StatisticsGen}
    \end{itemize}
  \item
    \hyperref[4-4]{4.4 - Inferring the Schema}

    \begin{itemize}
    \tightlist
    \item
      \hyperref[ex-4]{Exercise 4 - SchemaGen}
    \end{itemize}
  \item
    \hyperref[4-5]{4.5 - Curating the Schema}

    \begin{itemize}
    \tightlist
    \item
      \hyperref[ex-5]{Exercise 5 - Curating the Schema}
    \end{itemize}
  \item
    \hyperref[4-6]{4.6 - Schema Environments}

    \begin{itemize}
    \tightlist
    \item
      \hyperref[ex-6]{Exercise 6 - Define the serving environment}
    \end{itemize}
  \item
    \hyperref[4-7]{4.7 - Generate new statistics using the updated schema}

    \begin{itemize}
    \tightlist
    \item
      \hyperref[ex-7]{Exercise 7 - ImporterNode}
    \item
      \hyperref[ex-8]{Exercise 8 - StatisticsGen with the new schema}
    \end{itemize}
  \item
    \hyperref[4-8]{4.8 - Check anomalies}

    \begin{itemize}
    \tightlist
    \item
      \hyperref[ex-9]{Exercise 9 - ExampleValidator}
    \end{itemize}
  \item
    \hyperref[4-9]{4.9 - Feature Engineering}

    \begin{itemize}
    \tightlist
    \item
      \hyperref[ex-10]{Exercise 10 - preprocessing function}
    \item
      \hyperref[ex-11]{Exercise 11 - Transform}
    \end{itemize}
  \end{itemize}
\item
  \hyperref[5]{5 - ML Metadata}

  \begin{itemize}
  \tightlist
  \item
    \hyperref[5-1]{5.1 - Accessing stored artifacts}
  \item
    \hyperref[5-2]{5.2 - Tracking artifacts}

    \begin{itemize}
    \tightlist
    \item
      \hyperref[ex-12]{Exercise 12 - Get parent artifacts}
    \end{itemize}
  \end{itemize}
\end{itemize}

    \#\# 1 - Imports

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{2}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}
\PY{k+kn}{import} \PY{n+nn}{tfx}

\PY{c+c1}{\PYZsh{} TFX components}
\PY{k+kn}{from} \PY{n+nn}{tfx}\PY{n+nn}{.}\PY{n+nn}{components} \PY{k+kn}{import} \PY{n}{CsvExampleGen}
\PY{k+kn}{from} \PY{n+nn}{tfx}\PY{n+nn}{.}\PY{n+nn}{components} \PY{k+kn}{import} \PY{n}{ExampleValidator}
\PY{k+kn}{from} \PY{n+nn}{tfx}\PY{n+nn}{.}\PY{n+nn}{components} \PY{k+kn}{import} \PY{n}{SchemaGen}
\PY{k+kn}{from} \PY{n+nn}{tfx}\PY{n+nn}{.}\PY{n+nn}{components} \PY{k+kn}{import} \PY{n}{StatisticsGen}
\PY{k+kn}{from} \PY{n+nn}{tfx}\PY{n+nn}{.}\PY{n+nn}{components} \PY{k+kn}{import} \PY{n}{Transform}
\PY{k+kn}{from} \PY{n+nn}{tfx}\PY{n+nn}{.}\PY{n+nn}{components} \PY{k+kn}{import} \PY{n}{ImporterNode}

\PY{c+c1}{\PYZsh{} TFX libraries}
\PY{k+kn}{import} \PY{n+nn}{tensorflow\PYZus{}data\PYZus{}validation} \PY{k}{as} \PY{n+nn}{tfdv}
\PY{k+kn}{import} \PY{n+nn}{tensorflow\PYZus{}transform} \PY{k}{as} \PY{n+nn}{tft}
\PY{k+kn}{from} \PY{n+nn}{tfx}\PY{n+nn}{.}\PY{n+nn}{orchestration}\PY{n+nn}{.}\PY{n+nn}{experimental}\PY{n+nn}{.}\PY{n+nn}{interactive}\PY{n+nn}{.}\PY{n+nn}{interactive\PYZus{}context} \PY{k+kn}{import} \PY{n}{InteractiveContext}

\PY{c+c1}{\PYZsh{} For performing feature selection}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{feature\PYZus{}selection} \PY{k+kn}{import} \PY{n}{SelectKBest}\PY{p}{,} \PY{n}{f\PYZus{}classif}

\PY{c+c1}{\PYZsh{} For feature visualization}
\PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt} 
\PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sns}

\PY{c+c1}{\PYZsh{} Utilities}
\PY{k+kn}{from} \PY{n+nn}{tensorflow}\PY{n+nn}{.}\PY{n+nn}{python}\PY{n+nn}{.}\PY{n+nn}{lib}\PY{n+nn}{.}\PY{n+nn}{io} \PY{k+kn}{import} \PY{n}{file\PYZus{}io}
\PY{k+kn}{from} \PY{n+nn}{tensorflow\PYZus{}metadata}\PY{n+nn}{.}\PY{n+nn}{proto}\PY{n+nn}{.}\PY{n+nn}{v0} \PY{k+kn}{import} \PY{n}{schema\PYZus{}pb2}
\PY{k+kn}{from} \PY{n+nn}{google}\PY{n+nn}{.}\PY{n+nn}{protobuf}\PY{n+nn}{.}\PY{n+nn}{json\PYZus{}format} \PY{k+kn}{import} \PY{n}{MessageToDict}
\PY{k+kn}{from}  \PY{n+nn}{tfx}\PY{n+nn}{.}\PY{n+nn}{proto} \PY{k+kn}{import} \PY{n}{example\PYZus{}gen\PYZus{}pb2}
\PY{k+kn}{from} \PY{n+nn}{tfx}\PY{n+nn}{.}\PY{n+nn}{types} \PY{k+kn}{import} \PY{n}{standard\PYZus{}artifacts}
\PY{k+kn}{import} \PY{n+nn}{os}
\PY{k+kn}{import} \PY{n+nn}{pprint}
\PY{k+kn}{import} \PY{n+nn}{tempfile}
\PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}

\PY{c+c1}{\PYZsh{} To ignore warnings from TF}
\PY{n}{tf}\PY{o}{.}\PY{n}{get\PYZus{}logger}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{setLevel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ERROR}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} For formatting print statements}
\PY{n}{pp} \PY{o}{=} \PY{n}{pprint}\PY{o}{.}\PY{n}{PrettyPrinter}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display versions of TF and TFX related packages}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TensorFlow version: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{\PYZus{}\PYZus{}version\PYZus{}\PYZus{}}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TFX version: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{tfx}\PY{o}{.}\PY{n}{\PYZus{}\PYZus{}version\PYZus{}\PYZus{}}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TensorFlow Data Validation version: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{tfdv}\PY{o}{.}\PY{n}{\PYZus{}\PYZus{}version\PYZus{}\PYZus{}}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TensorFlow Transform version: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{tft}\PY{o}{.}\PY{n}{\PYZus{}\PYZus{}version\PYZus{}\PYZus{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
TensorFlow version: 2.3.1
TFX version: 0.24.0
TensorFlow Data Validation version: 0.24.1
TensorFlow Transform version: 0.24.1
    \end{Verbatim}

    \#\# 2 - Load the dataset

You are going to use a variant of the
\href{https://archive.ics.uci.edu/ml/datasets/covertype}{Cover Type}
dataset. This can be used to train a model that predicts the forest
cover type based on cartographic variables. You can read more about the
\emph{original} dataset
\href{https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.info}{here}
and we've outlined the data columns below:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.20}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.27}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.11}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.42}}@{}}
\toprule
Column Name & Variable Type & Units / Range & Description \\
\midrule
\endhead
Elevation & quantitative & meters & Elevation in meters \\
Aspect & quantitative & azimuth & Aspect in degrees azimuth \\
Slope & quantitative & degrees & Slope in degrees \\
Horizontal\_Distance\_To\_Hydrology & quantitative & meters & Horz Dist
to nearest surface water features \\
Vertical\_Distance\_To\_Hydrology & quantitative & meters & Vert Dist to
nearest surface water features \\
Horizontal\_Distance\_To\_Roadways & quantitative & meters & Horz Dist
to nearest roadway \\
Hillshade\_9am & quantitative & 0 to 255 index & Hillshade index at 9am,
summer solstice \\
Hillshade\_Noon & quantitative & 0 to 255 index & Hillshade index at
noon, summer soltice \\
Hillshade\_3pm & quantitative & 0 to 255 index & Hillshade index at 3pm,
summer solstice \\
Horizontal\_Distance\_To\_Fire\_Points & quantitative & meters & Horz
Dist to nearest wildfire ignition points \\
Wilderness\_Area (4 binary columns) & qualitative & 0 (absence) or 1
(presence) & Wilderness area designation \\
Soil\_Type (40 binary columns) & qualitative & 0 (absence) or 1
(presence) & Soil Type designation \\
Cover\_Type (7 types) & integer & 1 to 7 & Forest Cover Type
designation \\
\bottomrule
\end{longtable}

As you may notice, the qualitative data has already been one-hot encoded
(e.g.~\texttt{Soil\_Type} has 40 binary columns where a \texttt{1}
indicates presence of a feature). For learning, we will use a modified
version of this dataset that shows a more raw format. This will let you
practice your skills in handling different data types. You can see the
code for preparing the dataset
\href{https://github.com/GoogleCloudPlatform/mlops-on-gcp/blob/master/datasets/covertype/wrangle/prepare.ipynb}{here}
if you want but it is \textbf{not required for this assignment}. The
main changes include:

\begin{itemize}
\tightlist
\item
  Converting \texttt{Wilderness\_Area} and \texttt{Soil\_Type} to
  strings.
\item
  Converting the \texttt{Cover\_Type} range to {[}0, 6{]}
\end{itemize}

Run the next cells to load the \textbf{modified} dataset to your
workspace.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{3}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} \PYZsh{} OPTIONAL: Just in case you want to restart the lab workspace *from scratch*, you}
\PY{c+c1}{\PYZsh{} \PYZsh{} can uncomment and run this block to delete previously created files and}
\PY{c+c1}{\PYZsh{} \PYZsh{} directories. }

\PY{c+c1}{\PYZsh{} !rm \PYZhy{}rf pipeline}
\PY{c+c1}{\PYZsh{} !rm \PYZhy{}rf data}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Declare paths to the data}
\PY{n}{DATA\PYZus{}DIR} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./data}\PY{l+s+s1}{\PYZsq{}}
\PY{n}{TRAINING\PYZus{}DIR} \PY{o}{=} \PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{DATA\PYZus{}DIR}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{/training}\PY{l+s+s1}{\PYZsq{}}
\PY{n}{TRAINING\PYZus{}DATA} \PY{o}{=} \PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{TRAINING\PYZus{}DIR}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{/dataset.csv}\PY{l+s+s1}{\PYZsq{}}

\PY{c+c1}{\PYZsh{} Create the directory}
\PY{o}{!}mkdir \PYZhy{}p \PY{o}{\PYZob{}}TRAINING\PYZus{}DIR\PY{o}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{5}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} download the dataset}
\PY{o}{!}wget \PYZhy{}nc https://storage.googleapis.com/workshop\PYZhy{}datasets/covertype/full/dataset.csv \PYZhy{}P \PY{o}{\PYZob{}}TRAINING\PYZus{}DIR\PY{o}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
File ‘./data/training/dataset.csv’ already there; not retrieving.

    \end{Verbatim}

    \#\# 3 - Feature Selection

For your first task, you will reduce the number of features to feed to
the model. As mentioned in Week 2, this will help reduce the complexity
of your model and save resources while training. Let's assume that you
already have a baseline model that is trained on all features and you
want to see if reducing the number of features will generate a better
model. You will want to select a subset that has great predictive value
to the label (in this case the \texttt{Cover\_Type}). Let's do that in
the following cells.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{6}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Load the dataset to a dataframe}
\PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{n}{TRAINING\PYZus{}DATA}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Preview the dataset}
\PY{n}{df}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{6}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
   Elevation  Aspect  Slope  Horizontal\_Distance\_To\_Hydrology  \textbackslash{}
0       2596      51      3                               258
1       2590      56      2                               212
2       2804     139      9                               268
3       2785     155     18                               242
4       2595      45      2                               153

   Vertical\_Distance\_To\_Hydrology  Horizontal\_Distance\_To\_Roadways  \textbackslash{}
0                               0                              510
1                              -6                              390
2                              65                             3180
3                             118                             3090
4                              -1                              391

   Hillshade\_9am  Hillshade\_Noon  Hillshade\_3pm  \textbackslash{}
0            221             232            148
1            220             235            151
2            234             238            135
3            238             238            122
4            220             234            150

   Horizontal\_Distance\_To\_Fire\_Points Wilderness\_Area Soil\_Type  Cover\_Type
0                                6279           Rawah     C7745           4
1                                6225           Rawah     C7745           4
2                                6121           Rawah     C4744           1
3                                6211           Rawah     C7746           1
4                                6172           Rawah     C7745           4
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Show the data type of each column}
\PY{n}{df}\PY{o}{.}\PY{n}{dtypes}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
Elevation                              int64
Aspect                                 int64
Slope                                  int64
Horizontal\_Distance\_To\_Hydrology       int64
Vertical\_Distance\_To\_Hydrology         int64
Horizontal\_Distance\_To\_Roadways        int64
Hillshade\_9am                          int64
Hillshade\_Noon                         int64
Hillshade\_3pm                          int64
Horizontal\_Distance\_To\_Fire\_Points     int64
Wilderness\_Area                       object
Soil\_Type                             object
Cover\_Type                             int64
dtype: object
\end{Verbatim}
\end{tcolorbox}
        
    Looking at the data types of each column and the dataset description at
the start of this notebook, you can see that most of the features are
numeric and only two are not. This needs to be taken into account when
selecting the subset of features because numeric and categorical
features are scored differently. Let's create a temporary dataframe that
only contains the numeric features so we can use it in the next
sections.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{8}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Copy original dataset}
\PY{n}{df\PYZus{}num} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Categorical columns}
\PY{n}{cat\PYZus{}columns} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Wilderness\PYZus{}Area}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Soil\PYZus{}Type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Label column}
\PY{n}{label\PYZus{}column} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cover\PYZus{}Type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Drop the categorical and label columns}
\PY{n}{df\PYZus{}num}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{cat\PYZus{}columns}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{df\PYZus{}num}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{label\PYZus{}column}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Preview the resuls}
\PY{n}{df\PYZus{}num}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{8}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
   Elevation  Aspect  Slope  Horizontal\_Distance\_To\_Hydrology  \textbackslash{}
0       2596      51      3                               258
1       2590      56      2                               212
2       2804     139      9                               268
3       2785     155     18                               242
4       2595      45      2                               153

   Vertical\_Distance\_To\_Hydrology  Horizontal\_Distance\_To\_Roadways  \textbackslash{}
0                               0                              510
1                              -6                              390
2                              65                             3180
3                             118                             3090
4                              -1                              391

   Hillshade\_9am  Hillshade\_Noon  Hillshade\_3pm  \textbackslash{}
0            221             232            148
1            220             235            151
2            234             238            135
3            238             238            122
4            220             234            150

   Horizontal\_Distance\_To\_Fire\_Points
0                                6279
1                                6225
2                                6121
3                                6211
4                                6172
\end{Verbatim}
\end{tcolorbox}
        
    You will use scikit-learn's built-in modules to perform
\href{https://scikit-learn.org/stable/modules/feature_selection.html\#univariate-feature-selection}{univariate
feature selection} on our dataset's numeric attributes. First, you need
to prepare the input and target features:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{9}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Set the target values}
\PY{n}{y} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{n}{label\PYZus{}column}\PY{p}{]}\PY{o}{.}\PY{n}{values}

\PY{c+c1}{\PYZsh{} Set the input values}
\PY{n}{X} \PY{o}{=} \PY{n}{df\PYZus{}num}\PY{o}{.}\PY{n}{values}
\end{Verbatim}
\end{tcolorbox}

    Afterwards, you will use
\href{https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html\#sklearn.feature_selection.SelectKBest}{SelectKBest}
to score each input feature against the target variable. Be mindful of
the scoring function to pass in and make sure it is appropriate for the
input (numeric) and target (categorical) values.

    \#\#\# Exercise 1: Feature Selection

Complete the code below to select the top 8 features of the numeric
columns.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{10}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}

\PY{c+c1}{\PYZsh{} Create SelectKBest object using f\PYZus{}classif (ANOVA statistics) for 8 classes}
\PY{n}{select\PYZus{}k\PYZus{}best} \PY{o}{=} \PY{n}{SelectKBest}\PY{p}{(}\PY{n}{f\PYZus{}classif}\PY{p}{,} \PY{n}{k}\PY{o}{=}\PY{l+m+mi}{8}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Fit and transform the input data using select\PYZus{}k\PYZus{}best}
\PY{n}{X\PYZus{}new} \PY{o}{=} \PY{n}{select\PYZus{}k\PYZus{}best}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{y}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Extract the features which are selected using get\PYZus{}support API}
\PY{n}{features\PYZus{}mask} \PY{o}{=} \PY{n}{select\PYZus{}k\PYZus{}best}\PY{o}{.}\PY{n}{get\PYZus{}support}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}

\PY{c+c1}{\PYZsh{} Print the results}
\PY{n}{reqd\PYZus{}cols} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Columns}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{df\PYZus{}num}\PY{o}{.}\PY{n}{columns}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Retain}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{features\PYZus{}mask}\PY{p}{\PYZcb{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{reqd\PYZus{}cols}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
                              Columns  Retain
0                           Elevation    True
1                              Aspect   False
2                               Slope    True
3    Horizontal\_Distance\_To\_Hydrology    True
4      Vertical\_Distance\_To\_Hydrology    True
5     Horizontal\_Distance\_To\_Roadways    True
6                       Hillshade\_9am    True
7                      Hillshade\_Noon    True
8                       Hillshade\_3pm   False
9  Horizontal\_Distance\_To\_Fire\_Points    True
    \end{Verbatim}

    \textbf{Expected Output:}

\begin{verbatim}
                              Columns  Retain
0                           Elevation    True
1                              Aspect   False
2                               Slope    True
3    Horizontal_Distance_To_Hydrology    True
4      Vertical_Distance_To_Hydrology    True
5     Horizontal_Distance_To_Roadways    True
6                       Hillshade_9am    True
7                      Hillshade_Noon    True
8                       Hillshade_3pm   False
9  Horizontal_Distance_To_Fire_Points    True
\end{verbatim}

    If you got the expected results, you can now select this subset of
features from the original dataframe and save it to a new directory in
your workspace.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Set the paths to the reduced dataset}
\PY{n}{TRAINING\PYZus{}DIR\PYZus{}FSELECT} \PY{o}{=} \PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{TRAINING\PYZus{}DIR}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{/fselect}\PY{l+s+s1}{\PYZsq{}}
\PY{n}{TRAINING\PYZus{}DATA\PYZus{}FSELECT} \PY{o}{=} \PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{TRAINING\PYZus{}DIR\PYZus{}FSELECT}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{/dataset.csv}\PY{l+s+s1}{\PYZsq{}}

\PY{c+c1}{\PYZsh{} Create the directory}
\PY{o}{!}mkdir \PYZhy{}p \PY{o}{\PYZob{}}TRAINING\PYZus{}DIR\PYZus{}FSELECT\PY{o}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{12}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Get the feature names from SelectKBest}
\PY{n}{feature\PYZus{}names} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n}{df\PYZus{}num}\PY{o}{.}\PY{n}{columns}\PY{p}{[}\PY{n}{features\PYZus{}mask}\PY{p}{]}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Append the categorical and label columns}
\PY{n}{feature\PYZus{}names} \PY{o}{=} \PY{n}{feature\PYZus{}names} \PY{o}{+} \PY{n}{cat\PYZus{}columns} \PY{o}{+} \PY{n}{label\PYZus{}column}

\PY{c+c1}{\PYZsh{} Select the selected subset of columns}
\PY{n}{df\PYZus{}select} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{n}{feature\PYZus{}names}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Write CSV to the created directory}
\PY{n}{df\PYZus{}select}\PY{o}{.}\PY{n}{to\PYZus{}csv}\PY{p}{(}\PY{n}{TRAINING\PYZus{}DATA\PYZus{}FSELECT}\PY{p}{,} \PY{n}{index}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Preview the results}
\PY{n}{df\PYZus{}select}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{12}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
   Elevation  Slope  Horizontal\_Distance\_To\_Hydrology  \textbackslash{}
0       2596      3                               258
1       2590      2                               212
2       2804      9                               268
3       2785     18                               242
4       2595      2                               153

   Vertical\_Distance\_To\_Hydrology  Horizontal\_Distance\_To\_Roadways  \textbackslash{}
0                               0                              510
1                              -6                              390
2                              65                             3180
3                             118                             3090
4                              -1                              391

   Hillshade\_9am  Hillshade\_Noon  Horizontal\_Distance\_To\_Fire\_Points  \textbackslash{}
0            221             232                                6279
1            220             235                                6225
2            234             238                                6121
3            238             238                                6211
4            220             234                                6172

  Wilderness\_Area Soil\_Type  Cover\_Type
0           Rawah     C7745           4
1           Rawah     C7745           4
2           Rawah     C4744           1
3           Rawah     C7746           1
4           Rawah     C7745           4
\end{Verbatim}
\end{tcolorbox}
        
    \#\# 4 - Data Pipeline

With the selected subset of features prepared, you can now start
building the data pipeline. This involves ingesting, validating, and
transforming your data. You will be using the TFX components you've
already encountered in the ungraded labs and you can look them up here
in the
\href{https://www.tensorflow.org/tfx/api_docs/python/tfx/components}{official
documentation}.

    \#\#\# 4.1 - Setup the Interactive Context

As usual, you will first setup the Interactive Context so you can
manually execute the pipeline components from the notebook. You will
save the sqlite database in a pre-defined directory in your workspace.
Please do not modify this path because you will need this in a later
exercise involving ML Metadata.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{13}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Location of the pipeline metadata store}
\PY{n}{PIPELINE\PYZus{}DIR} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./pipeline}\PY{l+s+s1}{\PYZsq{}}

\PY{c+c1}{\PYZsh{} Declare the InteractiveContext and use a local sqlite file as the metadata store.}
\PY{n}{context} \PY{o}{=} \PY{n}{InteractiveContext}\PY{p}{(}\PY{n}{pipeline\PYZus{}root}\PY{o}{=}\PY{n}{PIPELINE\PYZus{}DIR}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
WARNING:absl:InteractiveContext metadata\_connection\_config not provided: using
SQLite ML Metadata database at ./pipeline/metadata.sqlite.
    \end{Verbatim}

    \#\#\# 4.2 - Generating Examples

The first step in the pipeline is to ingest the data. Using
\href{https://www.tensorflow.org/tfx/guide/examplegen}{ExampleGen}, you
can convert raw data to TFRecords for faster computation in the later
stages of the pipeline.

    \#\#\#\# Exercise 2: ExampleGen

Use \texttt{ExampleGen} to ingest the dataset we loaded earlier. Some
things to note:

\begin{itemize}
\tightlist
\item
  The input is in CSV format so you will need to use the appropriate
  type of \texttt{ExampleGen} to handle it.
\item
  This function accepts a \emph{directory} path to the training data and
  not the CSV file path itself.
\end{itemize}

This will take a couple of minutes to run.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} \PYZsh{} NOTE: Uncomment and run this if you get an error saying there are different }
\PY{c+c1}{\PYZsh{} \PYZsh{} headers in the dataset. This is usually because of the notebook checkpoints saved in }
\PY{c+c1}{\PYZsh{} \PYZsh{} that folder.}
\PY{c+c1}{\PYZsh{} !rm \PYZhy{}rf \PYZob{}TRAINING\PYZus{}DIR\PYZcb{}/.ipynb\PYZus{}checkpoints}
\PY{c+c1}{\PYZsh{} !rm \PYZhy{}rf \PYZob{}TRAINING\PYZus{}DIR\PYZus{}FSELECT\PYZcb{}/.ipynb\PYZus{}checkpoints}
\PY{c+c1}{\PYZsh{} !rm \PYZhy{}rf \PYZob{}SERVING\PYZus{}DIR\PYZcb{}/.ipynb\PYZus{}checkpoints}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{15}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE}

\PY{c+c1}{\PYZsh{} Instantiate ExampleGen with the input CSV dataset}
\PY{n}{example\PYZus{}gen} \PY{o}{=} \PY{n}{CsvExampleGen}\PY{p}{(}\PY{n}{input\PYZus{}base}\PY{o}{=}\PY{n}{TRAINING\PYZus{}DIR\PYZus{}FSELECT}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Run the component using the InteractiveContext instance}
\PY{n}{context}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{example\PYZus{}gen}\PY{p}{)}

\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE}
\end{Verbatim}
\end{tcolorbox}

    
    
            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{15}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
ExecutionResult(
    component\_id: CsvExampleGen
    execution\_id: 5
    outputs:
        examples: Channel(
            type\_name: Examples
            artifacts: [Artifact(artifact: id: 5
        type\_id: 5
        uri: "./pipeline/CsvExampleGen/examples/5"
        properties \{
          key: "split\_names"
          value \{
            string\_value: "[\textbackslash{}"train\textbackslash{}", \textbackslash{}"eval\textbackslash{}"]"
          \}
        \}
        custom\_properties \{
          key: "input\_fingerprint"
          value \{
            string\_value: "split:single\_split,num\_files:1,total\_bytes:27713036,x
or\_checksum:1626162109,sum\_checksum:1626162109"
          \}
        \}
        custom\_properties \{
          key: "payload\_format"
          value \{
            string\_value: "FORMAT\_TF\_EXAMPLE"
          \}
        \}
        custom\_properties \{
          key: "span"
          value \{
            string\_value: "0"
          \}
        \}
        custom\_properties \{
          key: "state"
          value \{
            string\_value: "published"
          \}
        \}
        , artifact\_type: id: 5
        name: "Examples"
        properties \{
          key: "span"
          value: INT
        \}
        properties \{
          key: "split\_names"
          value: STRING
        \}
        properties \{
          key: "version"
          value: INT
        \}
        )]
        ))
\end{Verbatim}
\end{tcolorbox}
        
    \#\#\# 4.3 - Computing Statistics

Next, you will compute the statistics of your data. This will allow you
to observe and analyze characteristics of your data through
visualizations provided by the integrated
\href{https://pair-code.github.io/facets/}{FACETS} library.

    \#\#\#\# Exercise 3: StatisticsGen

Use \href{https://www.tensorflow.org/tfx/guide/statsgen}{StatisticsGen}
to compute the statistics of the output examples of \texttt{ExampleGen}.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{16}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE}

\PY{c+c1}{\PYZsh{} Instantiate StatisticsGen with the ExampleGen ingested dataset}
\PY{n}{statistics\PYZus{}gen} \PY{o}{=} \PY{n}{StatisticsGen}\PY{p}{(}\PY{n}{examples}\PY{o}{=}\PY{n}{example\PYZus{}gen}\PY{o}{.}\PY{n}{outputs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{examples}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
    

\PY{c+c1}{\PYZsh{} Run the component}
\PY{n}{context}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{statistics\PYZus{}gen}\PY{p}{)}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{16}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
ExecutionResult(
    component\_id: StatisticsGen
    execution\_id: 6
    outputs:
        statistics: Channel(
            type\_name: ExampleStatistics
            artifacts: [Artifact(artifact: id: 6
        type\_id: 7
        uri: "./pipeline/StatisticsGen/statistics/6"
        properties \{
          key: "split\_names"
          value \{
            string\_value: "[\textbackslash{}"train\textbackslash{}", \textbackslash{}"eval\textbackslash{}"]"
          \}
        \}
        custom\_properties \{
          key: "name"
          value \{
            string\_value: "statistics"
          \}
        \}
        custom\_properties \{
          key: "producer\_component"
          value \{
            string\_value: "StatisticsGen"
          \}
        \}
        custom\_properties \{
          key: "state"
          value \{
            string\_value: "published"
          \}
        \}
        , artifact\_type: id: 7
        name: "ExampleStatistics"
        properties \{
          key: "span"
          value: INT
        \}
        properties \{
          key: "split\_names"
          value: STRING
        \}
        )]
        ))
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{17}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Display the results}
\PY{n}{context}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{n}{statistics\PYZus{}gen}\PY{o}{.}\PY{n}{outputs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{statistics}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    
    \begin{Verbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
    \end{Verbatim}

    
    
    \begin{Verbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
    \end{Verbatim}

    
    
    \begin{Verbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
    \end{Verbatim}

    
    
    \begin{Verbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
    \end{Verbatim}

    
    
    \begin{Verbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
    \end{Verbatim}

    
    Once you've loaded the display, you may notice that the \texttt{zeros}
column for \texttt{Cover\_type} is highlighted in red. The visualization
is letting us know that this might be a potential issue. In our case
though, we know that the \texttt{Cover\_Type} has a range of {[}0, 6{]}
so having zeros in this column is something we expect.

    \#\#\# 4.4 - Inferring the Schema

You will need to create a schema to validate incoming datasets during
training and serving. Fortunately, TFX allows you to infer a first draft
of this schema with the
\href{https://www.tensorflow.org/tfx/guide/schemagen}{SchemaGen}
component.

    \#\#\#\# Exercise 4: SchemaGen

Use \texttt{SchemaGen} to infer a schema based on the computed
statistics of \texttt{StatisticsGen}.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{18}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE}
\PY{c+c1}{\PYZsh{} Instantiate SchemaGen with the output statistics from the StatisticsGen}
\PY{n}{schema\PYZus{}gen} \PY{o}{=} \PY{n}{SchemaGen}\PY{p}{(}\PY{n}{statistics}\PY{o}{=}\PY{n}{statistics\PYZus{}gen}\PY{o}{.}\PY{n}{outputs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{statistics}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
    
    

\PY{c+c1}{\PYZsh{} Run the component}
\PY{n}{context}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{schema\PYZus{}gen}\PY{p}{)}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{18}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
ExecutionResult(
    component\_id: SchemaGen
    execution\_id: 7
    outputs:
        schema: Channel(
            type\_name: Schema
            artifacts: [Artifact(artifact: id: 7
        type\_id: 9
        uri: "./pipeline/SchemaGen/schema/7"
        custom\_properties \{
          key: "name"
          value \{
            string\_value: "schema"
          \}
        \}
        custom\_properties \{
          key: "producer\_component"
          value \{
            string\_value: "SchemaGen"
          \}
        \}
        custom\_properties \{
          key: "state"
          value \{
            string\_value: "published"
          \}
        \}
        , artifact\_type: id: 9
        name: "Schema"
        )]
        ))
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{19}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Visualize the output}
\PY{n}{context}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{n}{schema\PYZus{}gen}\PY{o}{.}\PY{n}{outputs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{schema}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    
    \begin{Verbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
    \end{Verbatim}

    
    
    \begin{Verbatim}[commandchars=\\\{\}]
                                        Type  Presence Valency  \textbackslash{}
Feature name                                                     
'Soil\_Type'                           STRING  required  single   
'Wilderness\_Area'                     STRING  required  single   
'Cover\_Type'                             INT  required  single   
'Elevation'                              INT  required  single   
'Hillshade\_9am'                          INT  required  single   
'Hillshade\_Noon'                         INT  required  single   
'Horizontal\_Distance\_To\_Fire\_Points'     INT  required  single   
'Horizontal\_Distance\_To\_Hydrology'       INT  required  single   
'Horizontal\_Distance\_To\_Roadways'        INT  required  single   
'Slope'                                  INT  required  single   
'Vertical\_Distance\_To\_Hydrology'         INT  required  single   

                                                 Domain  
Feature name                                             
'Soil\_Type'                                 'Soil\_Type'  
'Wilderness\_Area'                     'Wilderness\_Area'  
'Cover\_Type'                                          -  
'Elevation'                                           -  
'Hillshade\_9am'                                       -  
'Hillshade\_Noon'                                      -  
'Horizontal\_Distance\_To\_Fire\_Points'                  -  
'Horizontal\_Distance\_To\_Hydrology'                    -  
'Horizontal\_Distance\_To\_Roadways'                     -  
'Slope'                                               -  
'Vertical\_Distance\_To\_Hydrology'                      -  
    \end{Verbatim}

    
    
    \begin{Verbatim}[commandchars=\\\{\}]
                                                                                                                                                                                                                                                                                                                                                                                   Values
Domain                                                                                                                                                                                                                                                                                                                                                                                   
'Soil\_Type'        'C2702', 'C2703', 'C2704', 'C2705', 'C2706', 'C2717', 'C3501', 'C3502', 'C4201', 'C4703', 'C4704', 'C4744', 'C4758', 'C5101', 'C5151', 'C6101', 'C6102', 'C6731', 'C7101', 'C7102', 'C7103', 'C7201', 'C7202', 'C7700', 'C7701', 'C7702', 'C7709', 'C7710', 'C7745', 'C7746', 'C7755', 'C7756', 'C7757', 'C7790', 'C8703', 'C8707', 'C8708', 'C8771', 'C8772', 'C8776'
'Wilderness\_Area'  'Cache', 'Commanche', 'Neota', 'Rawah'                                                                                                                                                                                                                                                                                                                                
    \end{Verbatim}

    
    \#\#\# 4.5 - Curating the schema

You can see that the inferred schema is able to capture the data types
correctly and also able to show the expected values for the qualitative
(i.e.~string) data. You can still fine-tune this however. For instance,
we have features where we expect a certain range:

\begin{itemize}
\tightlist
\item
  \texttt{Hillshade\_9am}: 0 to 255
\item
  \texttt{Hillshade\_Noon}: 0 to 255
\item
  \texttt{Slope}: 0 to 90
\item
  \texttt{Cover\_Type}: 0 to 6
\end{itemize}

You want to update your schema to take note of these so the pipeline can
detect if invalid values are being fed to the model.

    \#\#\#\# Exercise 5: Curating the Schema

Use
\href{https://www.tensorflow.org/tfx/data_validation/get_started}{TFDV}
to update the inferred schema to restrict a range of values to the
features mentioned above.

Things to note: * You can use
\href{https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/set_domain}{tfdv.set\_domain()}
to define acceptable values for a particular feature. * These should
still be INT types after making your changes. * Declare
\texttt{Cover\_Type} as a \emph{categorical} variable. Unlike the other
four features, the integers 0 to 6 here correspond to a designated label
and not a quantitative measure. You can look at the available flags for
\texttt{set\_domain()} in the official doc to know how to set this.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{20}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{try}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} Get the schema uri}
    \PY{n}{schema\PYZus{}uri} \PY{o}{=} \PY{n}{schema\PYZus{}gen}\PY{o}{.}\PY{n}{outputs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{schema}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{\PYZus{}artifacts}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{uri}
    
\PY{c+c1}{\PYZsh{} for grading since context.run() does not work outside the notebook}
\PY{k}{except} \PY{n+ne}{IndexError}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{context.run() was no\PYZhy{}op}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
    \PY{n}{schema\PYZus{}path} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./pipeline/SchemaGen/schema}\PY{l+s+s1}{\PYZsq{}}
    \PY{n}{dir\PYZus{}id} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{listdir}\PY{p}{(}\PY{n}{schema\PYZus{}path}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
    \PY{n}{schema\PYZus{}uri} \PY{o}{=} \PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{schema\PYZus{}path}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{/}\PY{l+s+si}{\PYZob{}}\PY{n}{dir\PYZus{}id}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{21}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Get the schema pbtxt file from the SchemaGen output}
\PY{n}{schema} \PY{o}{=} \PY{n}{tfdv}\PY{o}{.}\PY{n}{load\PYZus{}schema\PYZus{}text}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{schema\PYZus{}uri}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{schema.pbtxt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{22}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}

\PY{c+c1}{\PYZsh{} Set the two `Hillshade` features to have a range of 0 to 255}
\PY{n}{tfdv}\PY{o}{.}\PY{n}{set\PYZus{}domain}\PY{p}{(}\PY{n}{schema}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Hillshade\PYZus{}9am}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{schema\PYZus{}pb2}\PY{o}{.}\PY{n}{IntDomain}\PY{p}{(}\PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Hillshade\PYZus{}9am}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n+nb}{min}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n+nb}{max}\PY{o}{=}\PY{l+m+mi}{255}\PY{p}{)}\PY{p}{)}
\PY{n}{tfdv}\PY{o}{.}\PY{n}{set\PYZus{}domain}\PY{p}{(}\PY{n}{schema}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Hillshade\PYZus{}Noon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{schema\PYZus{}pb2}\PY{o}{.}\PY{n}{IntDomain}\PY{p}{(}\PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Hillshade\PYZus{}Noon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n+nb}{min}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n+nb}{max}\PY{o}{=}\PY{l+m+mi}{255}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Set the `Slope` feature to have a range of 0 to 90}
\PY{n}{tfdv}\PY{o}{.}\PY{n}{set\PYZus{}domain}\PY{p}{(}\PY{n}{schema}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Slope}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{schema\PYZus{}pb2}\PY{o}{.}\PY{n}{IntDomain}\PY{p}{(}\PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Slope}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n+nb}{min}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n+nb}{max}\PY{o}{=}\PY{l+m+mi}{90}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Set `Cover\PYZus{}Type` to categorical having minimum value of 0 and maximum value of 6}
\PY{n}{tfdv}\PY{o}{.}\PY{n}{set\PYZus{}domain}\PY{p}{(}\PY{n}{schema}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cover\PYZus{}Type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{schema\PYZus{}pb2}\PY{o}{.}\PY{n}{IntDomain}\PY{p}{(}\PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cover\PYZus{}Type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n+nb}{min}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n+nb}{max}\PY{o}{=}\PY{l+m+mi}{6}\PY{p}{,} \PY{n}{is\PYZus{}categorical}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}

\PY{n}{tfdv}\PY{o}{.}\PY{n}{display\PYZus{}schema}\PY{p}{(}\PY{n}{schema}\PY{o}{=}\PY{n}{schema}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    
    \begin{Verbatim}[commandchars=\\\{\}]
                                        Type  Presence Valency  \textbackslash{}
Feature name                                                     
'Soil\_Type'                           STRING  required  single   
'Wilderness\_Area'                     STRING  required  single   
'Cover\_Type'                          INT     required  single   
'Elevation'                           INT     required  single   
'Hillshade\_9am'                       INT     required  single   
'Hillshade\_Noon'                      INT     required  single   
'Horizontal\_Distance\_To\_Fire\_Points'  INT     required  single   
'Horizontal\_Distance\_To\_Hydrology'    INT     required  single   
'Horizontal\_Distance\_To\_Roadways'     INT     required  single   
'Slope'                               INT     required  single   
'Vertical\_Distance\_To\_Hydrology'      INT     required  single   

                                                 Domain  
Feature name                                             
'Soil\_Type'                           'Soil\_Type'        
'Wilderness\_Area'                     'Wilderness\_Area'  
'Cover\_Type'                          [0,6]              
'Elevation'                           -                  
'Hillshade\_9am'                       [0,255]            
'Hillshade\_Noon'                      [0,255]            
'Horizontal\_Distance\_To\_Fire\_Points'  -                  
'Horizontal\_Distance\_To\_Hydrology'    -                  
'Horizontal\_Distance\_To\_Roadways'     -                  
'Slope'                               [0,90]             
'Vertical\_Distance\_To\_Hydrology'      -                  
    \end{Verbatim}

    
    
    \begin{Verbatim}[commandchars=\\\{\}]
                                                                                                                                                                                                                                                                                                                                                                                   Values
Domain                                                                                                                                                                                                                                                                                                                                                                                   
'Soil\_Type'        'C2702', 'C2703', 'C2704', 'C2705', 'C2706', 'C2717', 'C3501', 'C3502', 'C4201', 'C4703', 'C4704', 'C4744', 'C4758', 'C5101', 'C5151', 'C6101', 'C6102', 'C6731', 'C7101', 'C7102', 'C7103', 'C7201', 'C7202', 'C7700', 'C7701', 'C7702', 'C7709', 'C7710', 'C7745', 'C7746', 'C7755', 'C7756', 'C7757', 'C7790', 'C8703', 'C8707', 'C8708', 'C8771', 'C8772', 'C8776'
'Wilderness\_Area'  'Cache', 'Commanche', 'Neota', 'Rawah'                                                                                                                                                                                                                                                                                                                                
    \end{Verbatim}

    
    You should now see the ranges you declared in the \texttt{Domain} column
of the schema.

    \#\#\# 4.6 - Schema Environments

In supervised learning, we train the model to make predictions by
feeding a set of features with its corresponding label. Thus, our
training dataset will have both the input features and label, and the
schema is configured to detect these.

However, after training and you serve the model for inference, the
incoming data will no longer have the label. This will present problems
when validating the data using the current version of the schema. Let's
demonstrate that in the following cells. You will simulate a serving
dataset by getting subset of the training set and dropping the label
column (i.e.~\texttt{Cover\_Type}). Afterwards, you will validate this
serving dataset using the schema you curated earlier.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{23}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Declare paths to the serving data}
\PY{n}{SERVING\PYZus{}DIR} \PY{o}{=} \PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{DATA\PYZus{}DIR}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{/serving}\PY{l+s+s1}{\PYZsq{}}
\PY{n}{SERVING\PYZus{}DATA} \PY{o}{=} \PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{SERVING\PYZus{}DIR}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{/serving\PYZus{}dataset.csv}\PY{l+s+s1}{\PYZsq{}}

\PY{c+c1}{\PYZsh{} Create the directory}
\PY{o}{!}mkdir \PYZhy{}p \PY{o}{\PYZob{}}SERVING\PYZus{}DIR\PY{o}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{24}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Read a subset of the training dataset}
\PY{n}{serving\PYZus{}data} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{n}{TRAINING\PYZus{}DATA}\PY{p}{,} \PY{n}{nrows}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Drop the `Cover\PYZus{}Type` column}
\PY{n}{serving\PYZus{}data}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{columns}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cover\PYZus{}Type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Save the modified dataset}
\PY{n}{serving\PYZus{}data}\PY{o}{.}\PY{n}{to\PYZus{}csv}\PY{p}{(}\PY{n}{SERVING\PYZus{}DATA}\PY{p}{,} \PY{n}{index}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Delete unneeded variable from memory}
\PY{k}{del} \PY{n}{serving\PYZus{}data}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{25}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Declare StatsOptions to use the curated schema}
\PY{n}{stats\PYZus{}options} \PY{o}{=} \PY{n}{tfdv}\PY{o}{.}\PY{n}{StatsOptions}\PY{p}{(}\PY{n}{schema}\PY{o}{=}\PY{n}{schema}\PY{p}{,} \PY{n}{infer\PYZus{}type\PYZus{}from\PYZus{}schema}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Compute the statistics of the serving dataset}
\PY{n}{serving\PYZus{}stats} \PY{o}{=} \PY{n}{tfdv}\PY{o}{.}\PY{n}{generate\PYZus{}statistics\PYZus{}from\PYZus{}csv}\PY{p}{(}\PY{n}{SERVING\PYZus{}DATA}\PY{p}{,} \PY{n}{stats\PYZus{}options}\PY{o}{=}\PY{n}{stats\PYZus{}options}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Detect anomalies in the serving dataset}
\PY{n}{anomalies} \PY{o}{=} \PY{n}{tfdv}\PY{o}{.}\PY{n}{validate\PYZus{}statistics}\PY{p}{(}\PY{n}{serving\PYZus{}stats}\PY{p}{,} \PY{n}{schema}\PY{o}{=}\PY{n}{schema}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display the anomalies detected}
\PY{n}{tfdv}\PY{o}{.}\PY{n}{display\PYZus{}anomalies}\PY{p}{(}\PY{n}{anomalies}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    
    \begin{Verbatim}[commandchars=\\\{\}]
             Anomaly short description      Anomaly long description
Feature name                                                        
'Cover\_Type'  Column dropped            Column is completely missing
    \end{Verbatim}

    
    As expected, the missing column is flagged. To fix this, you need to
configure the schema to detect when it's being used for training or for
inference / serving. You can do this by setting
\href{https://www.tensorflow.org/tfx/tutorials/data_validation/tfdv_basic\#schema_environments}{schema
environments}.

    \#\#\#\# Exercise 6: Define the serving environment

Complete the code below to ignore the \texttt{Cover\_Type} feature when
validating in the \emph{SERVING} environment.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{26}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{schema}\PY{o}{.}\PY{n}{default\PYZus{}environment}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TRAINING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{} Hint: Create another default schema environment with name SERVING (pass in a string)}
\PY{n}{schema}\PY{o}{.}\PY{n}{default\PYZus{}environment}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SERVING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Remove Cover\PYZus{}Type feature from SERVING using TFDV}
\PY{c+c1}{\PYZsh{} Hint: Pass in the strings with the name of the feature and environment }
\PY{n}{tfdv}\PY{o}{.}\PY{n}{get\PYZus{}feature}\PY{p}{(}\PY{n}{schema}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cover\PYZus{}Type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{not\PYZus{}in\PYZus{}environment}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SERVING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}
\end{Verbatim}
\end{tcolorbox}

    If done correctly, running the cell below should show \emph{No
Anomalies}.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{27}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Validate the serving dataset statistics in the `SERVING` environment}
\PY{n}{anomalies} \PY{o}{=} \PY{n}{tfdv}\PY{o}{.}\PY{n}{validate\PYZus{}statistics}\PY{p}{(}\PY{n}{serving\PYZus{}stats}\PY{p}{,} \PY{n}{schema}\PY{o}{=}\PY{n}{schema}\PY{p}{,} \PY{n}{environment}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SERVING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display the anomalies detected}
\PY{n}{tfdv}\PY{o}{.}\PY{n}{display\PYZus{}anomalies}\PY{p}{(}\PY{n}{anomalies}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    
    \begin{Verbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
    \end{Verbatim}

    
    We can now save this curated schema in a local directory so we can
import it to our TFX pipeline.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{28}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Declare the path to the updated schema directory}
\PY{n}{UPDATED\PYZus{}SCHEMA\PYZus{}DIR} \PY{o}{=} \PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{PIPELINE\PYZus{}DIR}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{/updated\PYZus{}schema}\PY{l+s+s1}{\PYZsq{}}

\PY{c+c1}{\PYZsh{} Create the said directory}
\PY{o}{!}mkdir \PYZhy{}p \PY{o}{\PYZob{}}UPDATED\PYZus{}SCHEMA\PYZus{}DIR\PY{o}{\PYZcb{}}

\PY{c+c1}{\PYZsh{} Declare the path to the schema file}
\PY{n}{schema\PYZus{}file} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{UPDATED\PYZus{}SCHEMA\PYZus{}DIR}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{schema.pbtxt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Save the curated schema to the said file}
\PY{n}{tfdv}\PY{o}{.}\PY{n}{write\PYZus{}schema\PYZus{}text}\PY{p}{(}\PY{n}{schema}\PY{p}{,} \PY{n}{schema\PYZus{}file}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    As a sanity check, let's display the schema we just saved and verify
that it contains the changes we introduced. It should still show the
ranges in the \texttt{Domain} column and there should be two
environments available.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{29}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Load the schema from the directory we just created}
\PY{n}{new\PYZus{}schema} \PY{o}{=} \PY{n}{tfdv}\PY{o}{.}\PY{n}{load\PYZus{}schema\PYZus{}text}\PY{p}{(}\PY{n}{schema\PYZus{}file}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display the schema. Check that the Domain column still contains the ranges.}
\PY{n}{tfdv}\PY{o}{.}\PY{n}{display\PYZus{}schema}\PY{p}{(}\PY{n}{schema}\PY{o}{=}\PY{n}{new\PYZus{}schema}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    
    \begin{Verbatim}[commandchars=\\\{\}]
                                        Type  Presence Valency  \textbackslash{}
Feature name                                                     
'Soil\_Type'                           STRING  required  single   
'Wilderness\_Area'                     STRING  required  single   
'Cover\_Type'                          INT     required  single   
'Elevation'                           INT     required  single   
'Hillshade\_9am'                       INT     required  single   
'Hillshade\_Noon'                      INT     required  single   
'Horizontal\_Distance\_To\_Fire\_Points'  INT     required  single   
'Horizontal\_Distance\_To\_Hydrology'    INT     required  single   
'Horizontal\_Distance\_To\_Roadways'     INT     required  single   
'Slope'                               INT     required  single   
'Vertical\_Distance\_To\_Hydrology'      INT     required  single   

                                                 Domain  
Feature name                                             
'Soil\_Type'                           'Soil\_Type'        
'Wilderness\_Area'                     'Wilderness\_Area'  
'Cover\_Type'                          [0,6]              
'Elevation'                           -                  
'Hillshade\_9am'                       [0,255]            
'Hillshade\_Noon'                      [0,255]            
'Horizontal\_Distance\_To\_Fire\_Points'  -                  
'Horizontal\_Distance\_To\_Hydrology'    -                  
'Horizontal\_Distance\_To\_Roadways'     -                  
'Slope'                               [0,90]             
'Vertical\_Distance\_To\_Hydrology'      -                  
    \end{Verbatim}

    
    
    \begin{Verbatim}[commandchars=\\\{\}]
                                                                                                                                                                                                                                                                                                                                                                                   Values
Domain                                                                                                                                                                                                                                                                                                                                                                                   
'Soil\_Type'        'C2702', 'C2703', 'C2704', 'C2705', 'C2706', 'C2717', 'C3501', 'C3502', 'C4201', 'C4703', 'C4704', 'C4744', 'C4758', 'C5101', 'C5151', 'C6101', 'C6102', 'C6731', 'C7101', 'C7102', 'C7103', 'C7201', 'C7202', 'C7700', 'C7701', 'C7702', 'C7709', 'C7710', 'C7745', 'C7746', 'C7755', 'C7756', 'C7757', 'C7790', 'C8703', 'C8707', 'C8708', 'C8771', 'C8772', 'C8776'
'Wilderness\_Area'  'Cache', 'Commanche', 'Neota', 'Rawah'                                                                                                                                                                                                                                                                                                                                
    \end{Verbatim}

    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{30}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} The environment list should show `TRAINING` and `SERVING`.}
\PY{n}{new\PYZus{}schema}\PY{o}{.}\PY{n}{default\PYZus{}environment}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{30}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
['TRAINING', 'SERVING']
\end{Verbatim}
\end{tcolorbox}
        
    \#\#\# 4.7 - Generate new statistics using the updated schema

You will now compute the statistics using the schema you just curated.
Remember though that TFX components interact with each other by getting
artifact information from the metadata store. So you first have to
import the curated schema file into ML Metadata. You will do that by
using an
\href{https://www.tensorflow.org/tfx/guide/statsgen\#using_the_statsgen_component_with_a_schema}{ImporterNode}
to create an artifact representing the curated schema.

    \#\#\#\# Exercise 7: ImporterNode

Complete the code below to create a \texttt{Schema} artifact that points
to the curated schema directory. Pass in an \texttt{instance\_name} as
well and name it \texttt{import\_user\_schema}.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{31}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}

\PY{c+c1}{\PYZsh{} Use an ImporterNode to put the curated schema to ML Metadata}
\PY{n}{user\PYZus{}schema\PYZus{}importer} \PY{o}{=} \PY{n}{ImporterNode}\PY{p}{(}\PY{n}{instance\PYZus{}name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{import\PYZus{}user\PYZus{}schema}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                   \PY{n}{source\PYZus{}uri}\PY{o}{=}\PY{n}{UPDATED\PYZus{}SCHEMA\PYZus{}DIR}\PY{p}{,}
                                   \PY{n}{artifact\PYZus{}type}\PY{o}{=}\PY{n}{standard\PYZus{}artifacts}\PY{o}{.}\PY{n}{Schema}\PY{p}{)}
    
    
    
\PY{c+c1}{\PYZsh{} Run the component}
\PY{n}{context}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{user\PYZus{}schema\PYZus{}importer}\PY{p}{,} \PY{n}{enable\PYZus{}cache}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}

\PY{n}{context}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{n}{user\PYZus{}schema\PYZus{}importer}\PY{o}{.}\PY{n}{outputs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{result}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    
    \begin{Verbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
    \end{Verbatim}

    
    
    \begin{Verbatim}[commandchars=\\\{\}]
                                        Type  Presence Valency  \textbackslash{}
Feature name                                                     
'Soil\_Type'                           STRING  required  single   
'Wilderness\_Area'                     STRING  required  single   
'Cover\_Type'                          INT     required  single   
'Elevation'                           INT     required  single   
'Hillshade\_9am'                       INT     required  single   
'Hillshade\_Noon'                      INT     required  single   
'Horizontal\_Distance\_To\_Fire\_Points'  INT     required  single   
'Horizontal\_Distance\_To\_Hydrology'    INT     required  single   
'Horizontal\_Distance\_To\_Roadways'     INT     required  single   
'Slope'                               INT     required  single   
'Vertical\_Distance\_To\_Hydrology'      INT     required  single   

                                                 Domain  
Feature name                                             
'Soil\_Type'                           'Soil\_Type'        
'Wilderness\_Area'                     'Wilderness\_Area'  
'Cover\_Type'                          [0,6]              
'Elevation'                           -                  
'Hillshade\_9am'                       [0,255]            
'Hillshade\_Noon'                      [0,255]            
'Horizontal\_Distance\_To\_Fire\_Points'  -                  
'Horizontal\_Distance\_To\_Hydrology'    -                  
'Horizontal\_Distance\_To\_Roadways'     -                  
'Slope'                               [0,90]             
'Vertical\_Distance\_To\_Hydrology'      -                  
    \end{Verbatim}

    
    
    \begin{Verbatim}[commandchars=\\\{\}]
                                                                                                                                                                                                                                                                                                                                                                                   Values
Domain                                                                                                                                                                                                                                                                                                                                                                                   
'Soil\_Type'        'C2702', 'C2703', 'C2704', 'C2705', 'C2706', 'C2717', 'C3501', 'C3502', 'C4201', 'C4703', 'C4704', 'C4744', 'C4758', 'C5101', 'C5151', 'C6101', 'C6102', 'C6731', 'C7101', 'C7102', 'C7103', 'C7201', 'C7202', 'C7700', 'C7701', 'C7702', 'C7709', 'C7710', 'C7745', 'C7746', 'C7755', 'C7756', 'C7757', 'C7790', 'C8703', 'C8707', 'C8708', 'C8771', 'C8772', 'C8776'
'Wilderness\_Area'  'Cache', 'Commanche', 'Neota', 'Rawah'                                                                                                                                                                                                                                                                                                                                
    \end{Verbatim}

    
    With the artifact successfully created, you can now use
\texttt{StatisticsGen} and pass in a \texttt{schema} parameter to use
the curated schema.

\#\#\#\# Exercise 8: Statistics with the new schema

Use \texttt{StatisticsGen} to compute the statistics with the schema you
updated in the previous section.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{35}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{} Use StatisticsGen to compute the statistics using the curated schema}
\PY{n}{statistics\PYZus{}gen\PYZus{}updated} \PY{o}{=} \PY{n}{StatisticsGen}\PY{p}{(}\PY{n}{examples}\PY{o}{=}\PY{n}{example\PYZus{}gen}\PY{o}{.}\PY{n}{outputs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{examples}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
                                      \PY{n}{schema}\PY{o}{=}\PY{n}{user\PYZus{}schema\PYZus{}importer}\PY{o}{.}\PY{n}{outputs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{result}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
    
    

\PY{c+c1}{\PYZsh{} Run the component}
\PY{n}{context}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{statistics\PYZus{}gen\PYZus{}updated}\PY{p}{)}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{35}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
ExecutionResult(
    component\_id: StatisticsGen
    execution\_id: 9
    outputs:
        statistics: Channel(
            type\_name: ExampleStatistics
            artifacts: [Artifact(artifact: id: 8
        type\_id: 7
        uri: "./pipeline/StatisticsGen/statistics/9"
        properties \{
          key: "split\_names"
          value \{
            string\_value: "[\textbackslash{}"train\textbackslash{}", \textbackslash{}"eval\textbackslash{}"]"
          \}
        \}
        custom\_properties \{
          key: "name"
          value \{
            string\_value: "statistics"
          \}
        \}
        custom\_properties \{
          key: "producer\_component"
          value \{
            string\_value: "StatisticsGen"
          \}
        \}
        custom\_properties \{
          key: "state"
          value \{
            string\_value: "published"
          \}
        \}
        , artifact\_type: id: 7
        name: "ExampleStatistics"
        properties \{
          key: "span"
          value: INT
        \}
        properties \{
          key: "split\_names"
          value: STRING
        \}
        )]
        ))
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{37}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{context}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{n}{statistics\PYZus{}gen\PYZus{}updated}\PY{o}{.}\PY{n}{outputs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{statistics}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    
    \begin{Verbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
    \end{Verbatim}

    
    
    \begin{Verbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
    \end{Verbatim}

    
    
    \begin{Verbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
    \end{Verbatim}

    
    
    \begin{Verbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
    \end{Verbatim}

    
    
    \begin{Verbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
    \end{Verbatim}

    
    The chart will look mostly the same from the previous runs but you can
see that the \texttt{Cover\ Type} is now under the categorical features.
That shows that \texttt{StatisticsGen} is indeed using the updated
schema.

    \#\#\# 4.8 - Check anomalies

You will now check if the dataset has any anomalies with respect to the
schema. You can do that easily with the
\href{https://www.tensorflow.org/tfx/guide/exampleval}{ExampleValidator}
component.

    \#\#\#\# Exercise 9: ExampleValidator

Check if there are any anomalies using \texttt{ExampleValidator}. You
will need to pass in the updated statistics and schema from the previous
sections.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{41}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}

\PY{n}{example\PYZus{}validator} \PY{o}{=} \PY{n}{ExampleValidator}\PY{p}{(}\PY{n}{statistics}\PY{o}{=}\PY{n}{statistics\PYZus{}gen\PYZus{}updated}\PY{o}{.}\PY{n}{outputs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{statistics}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
                                    \PY{n}{schema}\PY{o}{=}\PY{n}{user\PYZus{}schema\PYZus{}importer}\PY{o}{.}\PY{n}{outputs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{result}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
    
    

\PY{c+c1}{\PYZsh{} Run the component.}
\PY{n}{context}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{example\PYZus{}validator}\PY{p}{)}

\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{41}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
ExecutionResult(
    component\_id: ExampleValidator
    execution\_id: 10
    outputs:
        anomalies: Channel(
            type\_name: ExampleAnomalies
            artifacts: [Artifact(artifact: id: 9
        type\_id: 12
        uri: "./pipeline/ExampleValidator/anomalies/10"
        properties \{
          key: "split\_names"
          value \{
            string\_value: "[\textbackslash{}"train\textbackslash{}", \textbackslash{}"eval\textbackslash{}"]"
          \}
        \}
        custom\_properties \{
          key: "name"
          value \{
            string\_value: "anomalies"
          \}
        \}
        custom\_properties \{
          key: "producer\_component"
          value \{
            string\_value: "ExampleValidator"
          \}
        \}
        custom\_properties \{
          key: "state"
          value \{
            string\_value: "published"
          \}
        \}
        , artifact\_type: id: 12
        name: "ExampleAnomalies"
        properties \{
          key: "span"
          value: INT
        \}
        properties \{
          key: "split\_names"
          value: STRING
        \}
        )]
        ))
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{42}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Visualize the results}
\PY{n}{context}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{n}{example\PYZus{}validator}\PY{o}{.}\PY{n}{outputs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{anomalies}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    
    \begin{Verbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
    \end{Verbatim}

    
    
    \begin{Verbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
    \end{Verbatim}

    
    
    \begin{Verbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
    \end{Verbatim}

    
    
    \begin{Verbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
    \end{Verbatim}

    
    
    \begin{Verbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
    \end{Verbatim}

    
    \#\#\# 4.10 - Feature engineering

You will now proceed to transforming your features to a form suitable
for training a model. This can include several methods such as scaling
and converting strings to vocabulary indices. It is important for these
transformations to be consistent across your training data, and also for
the serving data when the model is deployed for inference. TFX ensures
this by generating a graph that will process incoming data both during
training and inference.

Let's first declare the constants and utility function you will use for
the exercise.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{53}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Set the constants module filename}
\PY{n}{\PYZus{}cover\PYZus{}constants\PYZus{}module\PYZus{}file} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{cover\PYZus{}constants.py}\PY{l+s+s1}{\PYZsq{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{54}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}writefile} \PYZob{}\PYZus{}cover\PYZus{}constants\PYZus{}module\PYZus{}file\PYZcb{}

\PY{n}{SCALE\PYZus{}MINMAX\PYZus{}FEATURE\PYZus{}KEYS} \PY{o}{=} \PY{p}{[}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Horizontal\PYZus{}Distance\PYZus{}To\PYZus{}Hydrology}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Vertical\PYZus{}Distance\PYZus{}To\PYZus{}Hydrology}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{p}{]}

\PY{n}{SCALE\PYZus{}01\PYZus{}FEATURE\PYZus{}KEYS} \PY{o}{=} \PY{p}{[}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Hillshade\PYZus{}9am}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Hillshade\PYZus{}Noon}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Horizontal\PYZus{}Distance\PYZus{}To\PYZus{}Fire\PYZus{}Points}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{p}{]}

\PY{n}{SCALE\PYZus{}Z\PYZus{}FEATURE\PYZus{}KEYS} \PY{o}{=} \PY{p}{[}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Elevation}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Slope}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Horizontal\PYZus{}Distance\PYZus{}To\PYZus{}Roadways}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{p}{]}

\PY{n}{VOCAB\PYZus{}FEATURE\PYZus{}KEYS} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Wilderness\PYZus{}Area}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}

\PY{n}{HASH\PYZus{}STRING\PYZus{}FEATURE\PYZus{}KEYS} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Soil\PYZus{}Type}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}

\PY{n}{LABEL\PYZus{}KEY} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Cover\PYZus{}Type}\PY{l+s+s2}{\PYZdq{}}

\PY{c+c1}{\PYZsh{} Utility function for renaming the feature}
\PY{k}{def} \PY{n+nf}{transformed\PYZus{}name}\PY{p}{(}\PY{n}{key}\PY{p}{)}\PY{p}{:}
    \PY{k}{return} \PY{n}{key} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZus{}xf}\PY{l+s+s1}{\PYZsq{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Overwriting cover\_constants.py
    \end{Verbatim}

    Next you will define the \texttt{preprocessing\_fn} to apply
transformations to the features.

    \#\#\#\# Exercise 10: Preprocessing function

Complete the module to transform your features. Refer to the code
comments to get hints on what operations to perform.

Here are some links to the docs of the functions you will need to
complete this function:

\begin{itemize}
\tightlist
\item
  \href{https://www.tensorflow.org/tfx/transform/api_docs/python/tft/scale_by_min_max}{\texttt{tft.scale\_by\_min\_max}}
\item
  \href{https://www.tensorflow.org/tfx/transform/api_docs/python/tft/scale_to_0_1}{\texttt{tft.scale\_to\_0\_1}}
\item
  \href{https://www.tensorflow.org/tfx/transform/api_docs/python/tft/scale_to_z_score}{\texttt{tft.scale\_to\_z\_score}}
\item
  \href{https://www.tensorflow.org/tfx/transform/api_docs/python/tft/compute_and_apply_vocabulary}{\texttt{tft.compute\_and\_apply\_vocabulary}}
\item
  \href{https://www.tensorflow.org/tfx/transform/api_docs/python/tft/hash_strings}{\texttt{tft.hash\_strings}}
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{55}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Set the transform module filename}
\PY{n}{\PYZus{}cover\PYZus{}transform\PYZus{}module\PYZus{}file} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{cover\PYZus{}transform.py}\PY{l+s+s1}{\PYZsq{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{58}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}writefile} \PYZob{}\PYZus{}cover\PYZus{}transform\PYZus{}module\PYZus{}file\PYZcb{}

\PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}
\PY{k+kn}{import} \PY{n+nn}{tensorflow\PYZus{}transform} \PY{k}{as} \PY{n+nn}{tft}

\PY{k+kn}{import} \PY{n+nn}{cover\PYZus{}constants}

\PY{n}{\PYZus{}SCALE\PYZus{}MINMAX\PYZus{}FEATURE\PYZus{}KEYS} \PY{o}{=} \PY{n}{cover\PYZus{}constants}\PY{o}{.}\PY{n}{SCALE\PYZus{}MINMAX\PYZus{}FEATURE\PYZus{}KEYS}
\PY{n}{\PYZus{}SCALE\PYZus{}01\PYZus{}FEATURE\PYZus{}KEYS} \PY{o}{=} \PY{n}{cover\PYZus{}constants}\PY{o}{.}\PY{n}{SCALE\PYZus{}01\PYZus{}FEATURE\PYZus{}KEYS}
\PY{n}{\PYZus{}SCALE\PYZus{}Z\PYZus{}FEATURE\PYZus{}KEYS} \PY{o}{=} \PY{n}{cover\PYZus{}constants}\PY{o}{.}\PY{n}{SCALE\PYZus{}Z\PYZus{}FEATURE\PYZus{}KEYS}
\PY{n}{\PYZus{}VOCAB\PYZus{}FEATURE\PYZus{}KEYS} \PY{o}{=} \PY{n}{cover\PYZus{}constants}\PY{o}{.}\PY{n}{VOCAB\PYZus{}FEATURE\PYZus{}KEYS}
\PY{n}{\PYZus{}HASH\PYZus{}STRING\PYZus{}FEATURE\PYZus{}KEYS} \PY{o}{=} \PY{n}{cover\PYZus{}constants}\PY{o}{.}\PY{n}{HASH\PYZus{}STRING\PYZus{}FEATURE\PYZus{}KEYS}
\PY{n}{\PYZus{}LABEL\PYZus{}KEY} \PY{o}{=} \PY{n}{cover\PYZus{}constants}\PY{o}{.}\PY{n}{LABEL\PYZus{}KEY}
\PY{n}{\PYZus{}transformed\PYZus{}name} \PY{o}{=} \PY{n}{cover\PYZus{}constants}\PY{o}{.}\PY{n}{transformed\PYZus{}name}

\PY{k}{def} \PY{n+nf}{preprocessing\PYZus{}fn}\PY{p}{(}\PY{n}{inputs}\PY{p}{)}\PY{p}{:}

    \PY{n}{features\PYZus{}dict} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}

    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}
    \PY{k}{for} \PY{n}{feature} \PY{o+ow}{in} \PY{n}{\PYZus{}SCALE\PYZus{}MINMAX\PYZus{}FEATURE\PYZus{}KEYS}\PY{p}{:}
        \PY{n}{data\PYZus{}col} \PY{o}{=} \PY{n}{inputs}\PY{p}{[}\PY{n}{feature}\PY{p}{]} 
        \PY{c+c1}{\PYZsh{} Transform using scaling of min\PYZus{}max function}
        \PY{c+c1}{\PYZsh{} Hint: Use tft.scale\PYZus{}by\PYZus{}min\PYZus{}max by passing in the respective column}
        \PY{n}{features\PYZus{}dict}\PY{p}{[}\PY{n}{\PYZus{}transformed\PYZus{}name}\PY{p}{(}\PY{n}{feature}\PY{p}{)}\PY{p}{]} \PY{o}{=} \PY{n}{tft}\PY{o}{.}\PY{n}{scale\PYZus{}by\PYZus{}min\PYZus{}max}\PY{p}{(}\PY{n}{data\PYZus{}col}\PY{p}{)}

    \PY{k}{for} \PY{n}{feature} \PY{o+ow}{in} \PY{n}{\PYZus{}SCALE\PYZus{}01\PYZus{}FEATURE\PYZus{}KEYS}\PY{p}{:}
        \PY{n}{data\PYZus{}col} \PY{o}{=} \PY{n}{inputs}\PY{p}{[}\PY{n}{feature}\PY{p}{]} 
        \PY{c+c1}{\PYZsh{} Transform using scaling of 0 to 1 function}
        \PY{c+c1}{\PYZsh{} Hint: tft.scale\PYZus{}to\PYZus{}0\PYZus{}1}
        \PY{n}{features\PYZus{}dict}\PY{p}{[}\PY{n}{\PYZus{}transformed\PYZus{}name}\PY{p}{(}\PY{n}{feature}\PY{p}{)}\PY{p}{]} \PY{o}{=} \PY{n}{tft}\PY{o}{.}\PY{n}{scale\PYZus{}to\PYZus{}0\PYZus{}1}\PY{p}{(}\PY{n}{data\PYZus{}col}\PY{p}{)}

    \PY{k}{for} \PY{n}{feature} \PY{o+ow}{in} \PY{n}{\PYZus{}SCALE\PYZus{}Z\PYZus{}FEATURE\PYZus{}KEYS}\PY{p}{:}
        \PY{n}{data\PYZus{}col} \PY{o}{=} \PY{n}{inputs}\PY{p}{[}\PY{n}{feature}\PY{p}{]} 
        \PY{c+c1}{\PYZsh{} Transform using scaling to z score}
        \PY{c+c1}{\PYZsh{} Hint: tft.scale\PYZus{}to\PYZus{}z\PYZus{}score}
        \PY{n}{features\PYZus{}dict}\PY{p}{[}\PY{n}{\PYZus{}transformed\PYZus{}name}\PY{p}{(}\PY{n}{feature}\PY{p}{)}\PY{p}{]} \PY{o}{=} \PY{n}{tft}\PY{o}{.}\PY{n}{scale\PYZus{}to\PYZus{}z\PYZus{}score}\PY{p}{(}\PY{n}{data\PYZus{}col}\PY{p}{)}

    \PY{k}{for} \PY{n}{feature} \PY{o+ow}{in} \PY{n}{\PYZus{}VOCAB\PYZus{}FEATURE\PYZus{}KEYS}\PY{p}{:}
        \PY{n}{data\PYZus{}col} \PY{o}{=} \PY{n}{inputs}\PY{p}{[}\PY{n}{feature}\PY{p}{]} 
        \PY{c+c1}{\PYZsh{} Transform using vocabulary available in column}
        \PY{c+c1}{\PYZsh{} Hint: Use tft.compute\PYZus{}and\PYZus{}apply\PYZus{}vocabulary}
        \PY{n}{features\PYZus{}dict}\PY{p}{[}\PY{n}{\PYZus{}transformed\PYZus{}name}\PY{p}{(}\PY{n}{feature}\PY{p}{)}\PY{p}{]} \PY{o}{=} \PY{n}{tft}\PY{o}{.}\PY{n}{compute\PYZus{}and\PYZus{}apply\PYZus{}vocabulary}\PY{p}{(}\PY{n}{data\PYZus{}col}\PY{p}{)}

    \PY{k}{for} \PY{n}{feature} \PY{o+ow}{in} \PY{n}{\PYZus{}HASH\PYZus{}STRING\PYZus{}FEATURE\PYZus{}KEYS}\PY{p}{:}
        \PY{n}{data\PYZus{}col} \PY{o}{=} \PY{n}{inputs}\PY{p}{[}\PY{n}{feature}\PY{p}{]} 
        \PY{c+c1}{\PYZsh{} Transform by hashing strings into buckets}
        \PY{c+c1}{\PYZsh{} Hint: Use tft.hash\PYZus{}strings with the param hash\PYZus{}buckets set to 10}
        \PY{n}{features\PYZus{}dict}\PY{p}{[}\PY{n}{\PYZus{}transformed\PYZus{}name}\PY{p}{(}\PY{n}{feature}\PY{p}{)}\PY{p}{]} \PY{o}{=} \PY{n}{tft}\PY{o}{.}\PY{n}{hash\PYZus{}strings}\PY{p}{(}\PY{n}{data\PYZus{}col}\PY{p}{,} \PY{n}{hash\PYZus{}buckets}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}  }

    \PY{c+c1}{\PYZsh{} No change in the label}
    \PY{n}{features\PYZus{}dict}\PY{p}{[}\PY{n}{\PYZus{}LABEL\PYZus{}KEY}\PY{p}{]} \PY{o}{=} \PY{n}{inputs}\PY{p}{[}\PY{n}{\PYZus{}LABEL\PYZus{}KEY}\PY{p}{]}

    \PY{k}{return} \PY{n}{features\PYZus{}dict}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Overwriting cover\_transform.py
    \end{Verbatim}

    \#\#\#\# Exercise 11: Transform

Use the
\href{https://www.tensorflow.org/tfx/api_docs/python/tfx/components/Transform}{TFX
Transform component} to perform the transformations and generate the
transformation graph. You will need to pass in the dataset examples,
\emph{curated} schema, and the module that contains the preprocessing
function.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{59}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{} Instantiate the Transform component}
\PY{n}{transform} \PY{o}{=} \PY{n}{Transform}\PY{p}{(}\PY{n}{examples}\PY{o}{=}\PY{n}{example\PYZus{}gen}\PY{o}{.}\PY{n}{outputs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{examples}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
                      \PY{n}{schema}\PY{o}{=}\PY{n}{user\PYZus{}schema\PYZus{}importer}\PY{o}{.}\PY{n}{outputs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{result}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
                      \PY{n}{module\PYZus{}file}\PY{o}{=}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{abspath}\PY{p}{(}\PY{n}{\PYZus{}cover\PYZus{}transform\PYZus{}module\PYZus{}file}\PY{p}{)}
                     \PY{p}{)}
    
    
    
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}

\PY{c+c1}{\PYZsh{} Run the component}
\PY{n}{context}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{transform}\PY{p}{,} \PY{n}{enable\PYZus{}cache}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
WARNING:root:This output type hint will be ignored and not used for type-
checking purposes. Typically, output type hints for a PTransform are single (or
nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str,
Union[NoneType, \_Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType]]
instead.
WARNING:root:This output type hint will be ignored and not used for type-
checking purposes. Typically, output type hints for a PTransform are single (or
nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str,
Union[NoneType, \_Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType]]
instead.
WARNING:apache\_beam.typehints.typehints:Ignoring send\_type hint: <class
'NoneType'>
WARNING:apache\_beam.typehints.typehints:Ignoring return\_type hint: <class
'NoneType'>
WARNING:apache\_beam.typehints.typehints:Ignoring send\_type hint: <class
'NoneType'>
WARNING:apache\_beam.typehints.typehints:Ignoring return\_type hint: <class
'NoneType'>
WARNING:apache\_beam.typehints.typehints:Ignoring send\_type hint: <class
'NoneType'>
WARNING:apache\_beam.typehints.typehints:Ignoring return\_type hint: <class
'NoneType'>
WARNING:apache\_beam.typehints.typehints:Ignoring send\_type hint: <class
'NoneType'>
WARNING:apache\_beam.typehints.typehints:Ignoring return\_type hint: <class
'NoneType'>
WARNING:apache\_beam.typehints.typehints:Ignoring send\_type hint: <class
'NoneType'>
WARNING:apache\_beam.typehints.typehints:Ignoring return\_type hint: <class
'NoneType'>
WARNING:apache\_beam.typehints.typehints:Ignoring send\_type hint: <class
'NoneType'>
WARNING:apache\_beam.typehints.typehints:Ignoring return\_type hint: <class
'NoneType'>
    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{59}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
ExecutionResult(
    component\_id: Transform
    execution\_id: 14
    outputs:
        transform\_graph: Channel(
            type\_name: TransformGraph
            artifacts: [Artifact(artifact: id: 19
        type\_id: 14
        uri: "./pipeline/Transform/transform\_graph/14"
        custom\_properties \{
          key: "name"
          value \{
            string\_value: "transform\_graph"
          \}
        \}
        custom\_properties \{
          key: "producer\_component"
          value \{
            string\_value: "Transform"
          \}
        \}
        custom\_properties \{
          key: "state"
          value \{
            string\_value: "published"
          \}
        \}
        , artifact\_type: id: 14
        name: "TransformGraph"
        )]
        )
        transformed\_examples: Channel(
            type\_name: Examples
            artifacts: [Artifact(artifact: id: 20
        type\_id: 5
        uri: "./pipeline/Transform/transformed\_examples/14"
        properties \{
          key: "split\_names"
          value \{
            string\_value: "[\textbackslash{}"train\textbackslash{}", \textbackslash{}"eval\textbackslash{}"]"
          \}
        \}
        custom\_properties \{
          key: "name"
          value \{
            string\_value: "transformed\_examples"
          \}
        \}
        custom\_properties \{
          key: "producer\_component"
          value \{
            string\_value: "Transform"
          \}
        \}
        custom\_properties \{
          key: "state"
          value \{
            string\_value: "published"
          \}
        \}
        , artifact\_type: id: 5
        name: "Examples"
        properties \{
          key: "span"
          value: INT
        \}
        properties \{
          key: "split\_names"
          value: STRING
        \}
        properties \{
          key: "version"
          value: INT
        \}
        )]
        )
        updated\_analyzer\_cache: Channel(
            type\_name: TransformCache
            artifacts: [Artifact(artifact: id: 21
        type\_id: 15
        uri: "./pipeline/Transform/updated\_analyzer\_cache/14"
        custom\_properties \{
          key: "name"
          value \{
            string\_value: "updated\_analyzer\_cache"
          \}
        \}
        custom\_properties \{
          key: "producer\_component"
          value \{
            string\_value: "Transform"
          \}
        \}
        custom\_properties \{
          key: "state"
          value \{
            string\_value: "published"
          \}
        \}
        , artifact\_type: id: 15
        name: "TransformCache"
        )]
        ))
\end{Verbatim}
\end{tcolorbox}
        
    Let's inspect a few examples of the transformed dataset to see if the
transformations are done correctly.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{60}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{try}\PY{p}{:}
    \PY{n}{transform\PYZus{}uri} \PY{o}{=} \PY{n}{transform}\PY{o}{.}\PY{n}{outputs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{transformed\PYZus{}examples}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{uri}

\PY{c+c1}{\PYZsh{} for grading since context.run() does not work outside the notebook}
\PY{k}{except} \PY{n+ne}{IndexError}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{context.run() was no\PYZhy{}op}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
    \PY{n}{examples\PYZus{}path} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./pipeline/Transform/transformed\PYZus{}examples}\PY{l+s+s1}{\PYZsq{}}
    \PY{n}{dir\PYZus{}id} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{listdir}\PY{p}{(}\PY{n}{examples\PYZus{}path}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
    \PY{n}{transform\PYZus{}uri} \PY{o}{=} \PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{examples\PYZus{}path}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{/}\PY{l+s+si}{\PYZob{}}\PY{n}{dir\PYZus{}id}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{61}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Get the URI of the output artifact representing the transformed examples}
\PY{n}{train\PYZus{}uri} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{transform\PYZus{}uri}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Get the list of files in this directory (all compressed TFRecord files)}
\PY{n}{tfrecord\PYZus{}filenames} \PY{o}{=} \PY{p}{[}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{train\PYZus{}uri}\PY{p}{,} \PY{n}{name}\PY{p}{)}
                      \PY{k}{for} \PY{n}{name} \PY{o+ow}{in} \PY{n}{os}\PY{o}{.}\PY{n}{listdir}\PY{p}{(}\PY{n}{train\PYZus{}uri}\PY{p}{)}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Create a `TFRecordDataset` to read these files}
\PY{n}{transformed\PYZus{}dataset} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{TFRecordDataset}\PY{p}{(}\PY{n}{tfrecord\PYZus{}filenames}\PY{p}{,} \PY{n}{compression\PYZus{}type}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{GZIP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{62}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} import helper function to get examples from the dataset}
\PY{k+kn}{from} \PY{n+nn}{util} \PY{k+kn}{import} \PY{n}{get\PYZus{}records}

\PY{c+c1}{\PYZsh{} Get 3 records from the dataset}
\PY{n}{sample\PYZus{}records\PYZus{}xf} \PY{o}{=} \PY{n}{get\PYZus{}records}\PY{p}{(}\PY{n}{transformed\PYZus{}dataset}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Print the output}
\PY{n}{pp}\PY{o}{.}\PY{n}{pprint}\PY{p}{(}\PY{n}{sample\PYZus{}records\PYZus{}xf}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
[\{'features': \{'feature': \{'Cover\_Type': \{'int64List': \{'value': ['4']\}\},
                           'Elevation\_xf': \{'floatList': \{'value':
[-1.2982628]\}\},
                           'Hillshade\_9am\_xf': \{'floatList': \{'value':
[0.87007874]\}\},
                           'Hillshade\_Noon\_xf': \{'floatList': \{'value':
[0.9133858]\}\},
                           'Horizontal\_Distance\_To\_Fire\_Points\_xf':
\{'floatList': \{'value': [0.875366]\}\},
                           'Horizontal\_Distance\_To\_Hydrology\_xf': \{'floatList':
\{'value': [0.18468146]\}\},
                           'Horizontal\_Distance\_To\_Roadways\_xf': \{'floatList':
\{'value': [-1.1803539]\}\},
                           'Slope\_xf': \{'floatList': \{'value': [-1.483387]\}\},
                           'Soil\_Type\_xf': \{'int64List': \{'value': ['4']\}\},
                           'Vertical\_Distance\_To\_Hydrology\_xf': \{'floatList':
\{'value': [0.22351421]\}\},
                           'Wilderness\_Area\_xf': \{'int64List': \{'value':
['0']\}\}\}\}\},
 \{'features': \{'feature': \{'Cover\_Type': \{'int64List': \{'value': ['4']\}\},
                           'Elevation\_xf': \{'floatList': \{'value':
[-1.3197033]\}\},
                           'Hillshade\_9am\_xf': \{'floatList': \{'value':
[0.86614174]\}\},
                           'Hillshade\_Noon\_xf': \{'floatList': \{'value':
[0.9251968]\}\},
                           'Horizontal\_Distance\_To\_Fire\_Points\_xf':
\{'floatList': \{'value': [0.8678377]\}\},
                           'Horizontal\_Distance\_To\_Hydrology\_xf': \{'floatList':
\{'value': [0.15175375]\}\},
                           'Horizontal\_Distance\_To\_Roadways\_xf': \{'floatList':
\{'value': [-1.2572862]\}\},
                           'Slope\_xf': \{'floatList': \{'value': [-1.6169325]\}\},
                           'Soil\_Type\_xf': \{'int64List': \{'value': ['4']\}\},
                           'Vertical\_Distance\_To\_Hydrology\_xf': \{'floatList':
\{'value': [0.21576227]\}\},
                           'Wilderness\_Area\_xf': \{'int64List': \{'value':
['0']\}\}\}\}\},
 \{'features': \{'feature': \{'Cover\_Type': \{'int64List': \{'value': ['1']\}\},
                           'Elevation\_xf': \{'floatList': \{'value':
[-0.5549895]\}\},
                           'Hillshade\_9am\_xf': \{'floatList': \{'value':
[0.9212598]\}\},
                           'Hillshade\_Noon\_xf': \{'floatList': \{'value':
[0.93700784]\}\},
                           'Horizontal\_Distance\_To\_Fire\_Points\_xf':
\{'floatList': \{'value': [0.8533389]\}\},
                           'Horizontal\_Distance\_To\_Hydrology\_xf': \{'floatList':
\{'value': [0.19183965]\}\},
                           'Horizontal\_Distance\_To\_Roadways\_xf': \{'floatList':
\{'value': [0.53138816]\}\},
                           'Slope\_xf': \{'floatList': \{'value': [-0.6821134]\}\},
                           'Soil\_Type\_xf': \{'int64List': \{'value': ['4']\}\},
                           'Vertical\_Distance\_To\_Hydrology\_xf': \{'floatList':
\{'value': [0.30749354]\}\},
                           'Wilderness\_Area\_xf': \{'int64List': \{'value':
['0']\}\}\}\}\}]
    \end{Verbatim}

    \#\# 5 - ML Metadata

TFX uses \href{https://www.tensorflow.org/tfx/guide/mlmd}{ML Metadata}
under the hood to keep records of artifacts that each component uses.
This makes it easier to track how the pipeline is run so you can
troubleshoot if needed or want to reproduce results.

In this final section of the assignment, you will demonstrate going
through this metadata store to retrieve related artifacts. This skill is
useful for when you want to recall which inputs are fed to a particular
stage of the pipeline. For example, you can know where to locate the
schema used to perform feature transformation, or you can determine
which set of examples were used to train a model.

    You will start by importing the relevant modules and setting up the
connection to the metadata store. We have also provided some helper
functions for displaying artifact information and you can review its
code in the external \texttt{util.py} module in your lab workspace.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{63}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Import mlmd and utilities}
\PY{k+kn}{import} \PY{n+nn}{ml\PYZus{}metadata} \PY{k}{as} \PY{n+nn}{mlmd}
\PY{k+kn}{from} \PY{n+nn}{ml\PYZus{}metadata}\PY{n+nn}{.}\PY{n+nn}{proto} \PY{k+kn}{import} \PY{n}{metadata\PYZus{}store\PYZus{}pb2}
\PY{k+kn}{from} \PY{n+nn}{util} \PY{k+kn}{import} \PY{n}{display\PYZus{}types}\PY{p}{,} \PY{n}{display\PYZus{}artifacts}\PY{p}{,} \PY{n}{display\PYZus{}properties}

\PY{c+c1}{\PYZsh{} Get the connection config to connect to the metadata store}
\PY{n}{connection\PYZus{}config} \PY{o}{=} \PY{n}{context}\PY{o}{.}\PY{n}{metadata\PYZus{}connection\PYZus{}config}

\PY{c+c1}{\PYZsh{} Instantiate a MetadataStore instance with the connection config}
\PY{n}{store} \PY{o}{=} \PY{n}{mlmd}\PY{o}{.}\PY{n}{MetadataStore}\PY{p}{(}\PY{n}{connection\PYZus{}config}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Declare the base directory where All TFX artifacts are stored}
\PY{n}{base\PYZus{}dir} \PY{o}{=} \PY{n}{connection\PYZus{}config}\PY{o}{.}\PY{n}{sqlite}\PY{o}{.}\PY{n}{filename\PYZus{}uri}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{metadata.sqlite}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \#\#\#\# 5.1 - Accessing stored artifacts

With the connection setup, you can now interact with the metadata store.
For instance, you can retrieve all artifact types stored with the
\texttt{get\_artifact\_types()} function. For reference, the API is
documented
\href{https://www.tensorflow.org/tfx/ml_metadata/api_docs/python/mlmd/MetadataStore}{here}.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{64}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Get the artifact types}
\PY{n}{types} \PY{o}{=} \PY{n}{store}\PY{o}{.}\PY{n}{get\PYZus{}artifact\PYZus{}types}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display the results}
\PY{n}{display\PYZus{}types}\PY{p}{(}\PY{n}{types}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{64}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
   id               name
0  5   Examples
1  7   ExampleStatistics
2  9   Schema
3  12  ExampleAnomalies
4  14  TransformGraph
5  15  TransformCache
\end{Verbatim}
\end{tcolorbox}
        
    You can also get a list of artifacts for a particular type to see if
there are variations used in the pipeline. For example, you curated a
schema in an earlier part of the assignment so this should appear in the
records. Running the cell below should show at least two rows: one for
the inferred schema, and another for the updated schema. If you ran this
notebook before, then you might see more rows because of the different
schema artifacts saved under the \texttt{./SchemaGen/schema} directory.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{65}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Retrieve the transform graph list}
\PY{n}{schema\PYZus{}list} \PY{o}{=} \PY{n}{store}\PY{o}{.}\PY{n}{get\PYZus{}artifacts\PYZus{}by\PYZus{}type}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Schema}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display artifact properties from the results}
\PY{n}{display\PYZus{}artifacts}\PY{p}{(}\PY{n}{store}\PY{p}{,} \PY{n}{schema\PYZus{}list}\PY{p}{,} \PY{n}{base\PYZus{}dir}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{65}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
   artifact id    type                   uri
0  3            Schema  ./SchemaGen/schema/3
1  4            Schema  ./updated\_schema
2  7            Schema  ./SchemaGen/schema/7
\end{Verbatim}
\end{tcolorbox}
        
    Moreover, you can also get the properties of a particular artifact. TFX
declares some properties automatically for each of its components. You
will most likely see \texttt{name}, \texttt{state} and
\texttt{producer\_component} for each artifact type. Additional
properties are added where appropriate. For example, a
\texttt{split\_names} property is added in \texttt{ExampleStatistics}
artifacts to indicate which splits the statistics are generated for.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{66}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Get the latest TransformGraph artifact}
\PY{n}{statistics\PYZus{}artifact} \PY{o}{=} \PY{n}{store}\PY{o}{.}\PY{n}{get\PYZus{}artifacts\PYZus{}by\PYZus{}type}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ExampleStatistics}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Display the properties of the retrieved artifact}
\PY{n}{display\PYZus{}properties}\PY{p}{(}\PY{n}{store}\PY{p}{,} \PY{n}{statistics\PYZus{}artifact}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{66}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
             property              value
0  split\_names         ["train", "eval"]
1  name                statistics
2  state               published
3  producer\_component  StatisticsGen
\end{Verbatim}
\end{tcolorbox}
        
    \#\#\#\# 5.2 - Tracking artifacts

For this final exercise, you will build a function to return the parent
artifacts of a given one. For example, this should be able to list the
artifacts that were used to generate a particular
\texttt{TransformGraph} instance.

    \#\#\#\#\# Exercise 12: Get parent artifacts

Complete the code below to track the inputs of a particular artifact.

Tips:

\begin{itemize}
\item
  You may find
  \href{https://www.tensorflow.org/tfx/ml_metadata/api_docs/python/mlmd/MetadataStore\#get_events_by_artifact_ids}{get\_events\_by\_artifact\_ids()}
  and
  \href{https://www.tensorflow.org/tfx/ml_metadata/api_docs/python/mlmd/MetadataStore\#get_executions_by_id}{get\_events\_by\_execution\_ids()}
  useful here.
\item
  Some of the methods of the MetadataStore class (such as the two given
  above) only accepts iterables so remember to convert to a list (or
  set) if you only have an int (e.g.~pass \texttt{{[}x{]}} instead of
  \texttt{x}).
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{87}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{get\PYZus{}parent\PYZus{}artifacts}\PY{p}{(}\PY{n}{store}\PY{p}{,} \PY{n}{artifact}\PY{p}{)}\PY{p}{:}

    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}
    
    \PY{c+c1}{\PYZsh{} Get the artifact id of the input artifact}
    \PY{n}{artifact\PYZus{}id} \PY{o}{=} \PY{n}{artifact}\PY{o}{.}\PY{n}{id}
    \PY{c+c1}{\PYZsh{}artifact\PYZus{}id = store.get\PYZus{}artifact\PYZus{}by\PYZus{}id(artifact).id}
    
    \PY{c+c1}{\PYZsh{} Get events associated with the artifact id}
    \PY{n}{artifact\PYZus{}id\PYZus{}events} \PY{o}{=} \PY{n}{store}\PY{o}{.}\PY{n}{get\PYZus{}events\PYZus{}by\PYZus{}artifact\PYZus{}ids}\PY{p}{(}\PY{p}{[}\PY{n}{artifact\PYZus{}id}\PY{p}{]}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} From the `artifact\PYZus{}id\PYZus{}events`, get the execution ids of OUTPUT events.}
    \PY{c+c1}{\PYZsh{} Cast to a set to remove duplicates if any.}
    \PY{n}{execution\PYZus{}id} \PY{o}{=} \PY{n+nb}{set}\PY{p}{(} 
        \PY{n}{event}\PY{o}{.}\PY{n}{execution\PYZus{}id}
        \PY{k}{for} \PY{n}{event} \PY{o+ow}{in} \PY{n}{artifact\PYZus{}id\PYZus{}events}
        \PY{k}{if} \PY{n}{event}\PY{o}{.}\PY{n}{type} \PY{o}{==} \PY{n}{metadata\PYZus{}store\PYZus{}pb2}\PY{o}{.}\PY{n}{Event}\PY{o}{.}\PY{n}{OUTPUT}
    \PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} Get the events associated with the execution\PYZus{}id}
    \PY{n}{execution\PYZus{}id\PYZus{}events} \PY{o}{=} \PY{n}{store}\PY{o}{.}\PY{n}{get\PYZus{}events\PYZus{}by\PYZus{}execution\PYZus{}ids}\PY{p}{(}\PY{n}{execution\PYZus{}id}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} From execution\PYZus{}id\PYZus{}events, get the artifact ids of INPUT events.}
    \PY{c+c1}{\PYZsh{} Cast to a set to remove duplicates if any.}
    \PY{n}{parent\PYZus{}artifact\PYZus{}ids} \PY{o}{=} \PY{n+nb}{set}\PY{p}{(} 
        \PY{n}{event}\PY{o}{.}\PY{n}{artifact\PYZus{}id}
        \PY{k}{for} \PY{n}{event} \PY{o+ow}{in} \PY{n}{execution\PYZus{}id\PYZus{}events}
        \PY{k}{if} \PY{n}{event}\PY{o}{.}\PY{n}{type} \PY{o}{==} \PY{n}{metadata\PYZus{}store\PYZus{}pb2}\PY{o}{.}\PY{n}{Event}\PY{o}{.}\PY{n}{INPUT}
    \PY{p}{)}
    
    
    \PY{c+c1}{\PYZsh{} Get the list of artifacts associated with the parent\PYZus{}artifact\PYZus{}ids}
    \PY{n}{parent\PYZus{}artifact\PYZus{}list} \PY{o}{=} \PY{n}{store}\PY{o}{.}\PY{n}{get\PYZus{}artifacts\PYZus{}by\PYZus{}id}\PY{p}{(}\PY{n}{parent\PYZus{}artifact\PYZus{}ids}\PY{p}{)}
    

    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}
    
    \PY{k}{return} \PY{n}{parent\PYZus{}artifact\PYZus{}list}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{88}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Get an artifact instance from the metadata store}
\PY{n}{artifact\PYZus{}instance} \PY{o}{=} \PY{n}{store}\PY{o}{.}\PY{n}{get\PYZus{}artifacts\PYZus{}by\PYZus{}type}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TransformGraph}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Retrieve the parent artifacts of the instance}
\PY{n}{parent\PYZus{}artifacts} \PY{o}{=} \PY{n}{get\PYZus{}parent\PYZus{}artifacts}\PY{p}{(}\PY{n}{store}\PY{p}{,} \PY{n}{artifact\PYZus{}instance}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display the results}
\PY{n}{display\PYZus{}artifacts}\PY{p}{(}\PY{n}{store}\PY{p}{,} \PY{n}{parent\PYZus{}artifacts}\PY{p}{,} \PY{n}{base\PYZus{}dir}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{88}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
   artifact id      type                         uri
0  4            Schema    ./updated\_schema
1  5            Examples  ./CsvExampleGen/examples/5
\end{Verbatim}
\end{tcolorbox}
        
    \textbf{Expected Output:}

\emph{Note: The ID numbers may differ.}

\begin{longtable}[]{@{}lll@{}}
\toprule
artifact id & type & uri \\
\midrule
\endhead
1 & Examples & ./CsvExampleGen/examples/1 \\
4 & Schema & ./updated\_schema \\
\bottomrule
\end{longtable}

    \textbf{Congratulations!} You have now completed the assignment for this
week. You've demonstrated your skills in selecting features, performing
a data pipeline, and retrieving information from the metadata store.
Having the ability to put these all together will be critical when
working with production grade machine learning projects. For next week,
you will work on more data types and see how these can be prepared in an
ML pipeline. \textbf{Keep it up!}


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
