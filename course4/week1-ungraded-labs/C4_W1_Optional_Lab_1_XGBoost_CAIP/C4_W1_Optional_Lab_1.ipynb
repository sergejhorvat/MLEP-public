{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f61be264",
   "metadata": {},
   "source": [
    "# Ungraded Lab (Optional): Build, train, and deploy an XGBoost model on Cloud AI Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8ccd73",
   "metadata": {},
   "source": [
    "## 1: Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9851d5ea",
   "metadata": {},
   "source": [
    "In this lab, you will walk through a complete ML workflow on GCP. From a Cloud AI Platform Notebooks environment, you'll ingest data from a BigQuery public dataset, build and train an XGBoost model, and deploy the model to AI Platform for prediction.\n",
    "\n",
    "You'll learn how to:\n",
    "\n",
    "    Ingest and analyze a BigQuery dataset in AI Platform Notebooks\n",
    "    Build an XGBoost model\n",
    "    Deploy the XGBoost model to AI Platform and get predictions\n",
    "    The total cost to run this lab on Google Cloud is about $1.\n",
    "\n",
    "Tip: It is best to have at least two windows open when going through the instructions in this tutorial: at least one for navigating to the different parts of GCP (e.g. Storage, BigQuery, AI Platform Models) and one for the AI Platform Jupyter Notebook you will open in Step 2 below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394c3740",
   "metadata": {},
   "source": [
    "## 2 : Setup Your Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b2bab5",
   "metadata": {},
   "source": [
    "You'll need a Google Cloud Platform project to run this exercise. If you just enabled a GCP free trial, you should already have a project called 'My First Project'. If not, you can follow the instructions here to create a project.\n",
    "\n",
    "#### Step 1: Enable the Cloud AI Platform Models API\n",
    "\n",
    "Navigate to the AI Platform Models section of your Cloud Console and click Enable if it isn't already enabled.\n",
    "images/models_api\n",
    "\n",
    "#### Step 2: Enable the Compute Engine API\n",
    "\n",
    "Navigate to Compute Engine and select Enable if it isn't already enabled. You'll need this to create your notebook instance. (tip: After clicking Enable and it doesn't automatically refresh, you can just manually refresh the page after a minute to see if the API has been enabled. It should show \"API Enabled\".\n",
    "\n",
    "#### Step 3: Create an AI Platform Notebooks instance\n",
    "\n",
    "Navigate to AI Platform Notebooks section of your Cloud Console and click New Instance. Then select the latest Python instance type:\n",
    "\n",
    "#### Step 4: Install XGBoost\n",
    "\n",
    "Once your JupyterLab instance has opened, you'll need to add the XGBoost package.\n",
    "\n",
    "To do this, select Terminal from the launcher:  \n",
    "pip3 install xgboost==1.4.2  \n",
    "From there, you can open a Python 3 Notebook instance. You're ready to get started in your notebook!\n",
    "\n",
    "#### Step 5: Import Python packages\n",
    "\n",
    "For the rest of this codelab, run all the code snippets from your Jupyter notebook.\n",
    "\n",
    "In the first cell of your notebook, add the following imports and run the cell. You can run it by pressing the right arrow button in the top menu or pressing command-enter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "057e99cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3e97f3",
   "metadata": {},
   "source": [
    "You'll be using the Python client library for BigQuery to download the data into a Pandas DataFrame. The original dataset is 21GB and contains 123M rows. To keep things simple we'll only be using 10,000 rows from the dataset.\n",
    "\n",
    "Construct the query and preview the resulting DataFrame with the following code. Here we're getting 4 features from the original dataset, along with baby weight (the thing our model will predict). The dataset goes back many years but for this model we'll use only data from after 2000:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d2b8a5",
   "metadata": {},
   "source": [
    "## 3 : Exploring the BigQuery dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bedb34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>is_male</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.063611</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.687028</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.561856</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.561856</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.312733</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_pounds  is_male  mother_age  plurality  gestation_weeks\n",
       "0       7.063611     True          32          1             37.0\n",
       "1       4.687028     True          30          3             33.0\n",
       "2       7.561856     True          20          1             39.0\n",
       "3       7.561856     True          31          1             37.0\n",
       "4       7.312733     True          32          1             40.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"\"\"\n",
    "SELECT\n",
    "  weight_pounds,\n",
    "  is_male,\n",
    "  mother_age,\n",
    "  plurality,\n",
    "  gestation_weeks\n",
    "FROM\n",
    "  publicdata.samples.natality\n",
    "WHERE year > 2000\n",
    "LIMIT 10000\n",
    "\"\"\"\n",
    "df = bigquery.Client().query(query).to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdffecd4",
   "metadata": {},
   "source": [
    "If you get a 403 Forbidden error, it means you will need to enable the BigQuery API for your account. Search for BigQuery in the Search Bar and click Enable API. Kindly wait for it to be enabled before re-running the command above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dac5e3",
   "metadata": {},
   "source": [
    "This shows the mean, standard deviation, minimum, and other metrics for our numeric columns. Finally, let's get some data on our boolean column indicating the baby's gender. We can do this with Pandas' value_counts method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f61b1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     5096\n",
       "False    4904\n",
       "Name: is_male, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_male'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e75d743",
   "metadata": {},
   "source": [
    "## 4 : Prepare Data for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96870c6",
   "metadata": {},
   "source": [
    "In this section, we'll divide the data into train and test sets to prepare it for training our model.\n",
    "\n",
    "#### Step 1: Extract the label column\n",
    "\n",
    "First drop rows with null values from the dataset and shuffle the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98d0d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = shuffle(df, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e574677",
   "metadata": {},
   "source": [
    "Next, extract the label column into a separate variable and create a DataFrame with only our features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21376c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['weight_pounds']\n",
    "data = df.drop(columns=['weight_pounds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1caf5e8",
   "metadata": {},
   "source": [
    "Now if you preview our dataset by running data.head(), you should see the four features we'll be using for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e22aa1",
   "metadata": {},
   "source": [
    "#### Step 2: Convert categorical features to integers\n",
    "\n",
    "Since XGBoost requires all data to be numeric, we'll need to change how we're representing the data in the is_male column, which is currently True / False strings. We can do that simply by changing the type of that column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fab3ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_male'] = data['is_male'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5b860b",
   "metadata": {},
   "source": [
    "#### Step 3: Split data into train and test sets\n",
    "\n",
    "We'll use Scikit Learn's train_test_split utility which we imported at the beginning of the notebook to split our data into train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00f69263",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = data,labels\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ece1de",
   "metadata": {},
   "source": [
    "Now we're ready to build and train our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c453af14",
   "metadata": {},
   "source": [
    "## 5 : A quick XGBoost primer\n",
    "\n",
    "    XGBoost is a machine learning framework that uses decision trees and gradient boosting to build predictive models. It works by ensembling multiple decision trees together based on the score associated with different leaf nodes in a tree.\n",
    "\n",
    "The diagram below is a simplified visualization of an ensemble tree network for a model that evaluates whether or not someone will like a specific computer game (this is from the XGBoost docs):  \n",
    "<img src='xgboost.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ead24fa",
   "metadata": {},
   "source": [
    "Why are we using XGBoost for this model? While traditional neural networks have been shown to perform best on unstructured data like images and text, decision trees often perform extremely well on structured data like the birth weight dataset we'll be using."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db7e7aa",
   "metadata": {},
   "source": [
    "## 6 : Build, train, and evaluate an XGBoost model\n",
    "\n",
    "#### Step 1:\n",
    "Define and train the XGBoost model Creating a model in XGBoost is simple. We'll use the XGBRegressor class to create the model, and just need to pass the right objective parameter for our specific task. Here we're using a regression model since we're predicting a numerical value (baby's weight). If we were instead bucketing our data to determine if a baby weighed more or less than 6 pounds, we'd use a classification model.\n",
    "\n",
    "In this case we'll use reg:squarederror as our model's objective.\n",
    "\n",
    "The following code will create an XGBoost model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb7837f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9066ee",
   "metadata": {},
   "source": [
    "you can train the model with one line of code, calling the fit() method and passing it the training data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e68000a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13b5b1",
   "metadata": {},
   "source": [
    "#### Step 2: Evaluate your model on test data\n",
    "\n",
    "We can now use our trained model to generate predictions on our test data with the predict() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6057923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a98bae3",
   "metadata": {},
   "source": [
    "Let's see how the model performed on the first 20 values from our test set. Below we'll print the predicted baby weight along with the actual baby weight for each test example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc68e959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted weight:  7.9053507\n",
      "Actual weight:  9.43798943622\n",
      "\n",
      "Predicted weight:  7.5190206\n",
      "Actual weight:  8.56275425608\n",
      "\n",
      "Predicted weight:  6.360227\n",
      "Actual weight:  7.936641432\n",
      "\n",
      "Predicted weight:  7.8039613\n",
      "Actual weight:  7.87491199864\n",
      "\n",
      "Predicted weight:  7.218525\n",
      "Actual weight:  6.1883756943399995\n",
      "\n",
      "Predicted weight:  7.791048\n",
      "Actual weight:  9.62538235892\n",
      "\n",
      "Predicted weight:  7.593407\n",
      "Actual weight:  10.37495404972\n",
      "\n",
      "Predicted weight:  7.4427757\n",
      "Actual weight:  6.9996768185\n",
      "\n",
      "Predicted weight:  7.440815\n",
      "Actual weight:  7.7492485093\n",
      "\n",
      "Predicted weight:  7.926063\n",
      "Actual weight:  7.1319541757\n",
      "\n",
      "Predicted weight:  7.584514\n",
      "Actual weight:  7.68751907594\n",
      "\n",
      "Predicted weight:  7.761119\n",
      "Actual weight:  7.50012615324\n",
      "\n",
      "Predicted weight:  7.858591\n",
      "Actual weight:  5.1367707046\n",
      "\n",
      "Predicted weight:  2.1454005\n",
      "Actual weight:  2.68743497378\n",
      "\n",
      "Predicted weight:  7.747493\n",
      "Actual weight:  6.935742762519999\n",
      "\n",
      "Predicted weight:  6.832648\n",
      "Actual weight:  7.30391474006\n",
      "\n",
      "Predicted weight:  4.3678555\n",
      "Actual weight:  7.06361087448\n",
      "\n",
      "Predicted weight:  6.3810005\n",
      "Actual weight:  7.3744626639\n",
      "\n",
      "Predicted weight:  7.780418\n",
      "Actual weight:  6.6248909731\n",
      "\n",
      "Predicted weight:  8.02287\n",
      "Actual weight:  7.71617917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print('Predicted weight: ', y_pred[i])\n",
    "    print('Actual weight: ', y_test.iloc[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a447ee",
   "metadata": {},
   "source": [
    "#### Step 3: \n",
    "Save your model In order to deploy the model, run the following code to save it to a local file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3edf03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('model.bst')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a61b845",
   "metadata": {},
   "source": [
    "## 7 : Deploy model to Cloud AI Platform\n",
    "\n",
    "We've got our model working locally, but it would be nice if we could make predictions on it from anywhere (not just this notebook!). In this step we'll deploy it to the cloud.\n",
    "\n",
    "#### Step 1: Create a Cloud Storage bucket for our model\n",
    "\n",
    "Let's first define some environment variables that we'll be using throughout the rest of the tutorial. Fill in the values below with your PROJECT ID, the name of the cloud storage bucket you'd like to create (must be globally unique, you can use the project id as well), and the version name for the first version of your model.\n",
    "\n",
    "Tip: You can get the Project ID as shown by Laurence in the screencast or by running this command in a cell: !gcloud config list project --format \"value(core.project)\". You can use the result to fill in <YOUR_PROJECT_ID> below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2529b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update these to your own GCP project, model, and version names\n",
    "GCP_PROJECT = 'coursera-mlops-c4w1l3'\n",
    "MODEL_BUCKET = 'gs://coursera-mlops-c4w1l3'\n",
    "VERSION_NAME = 'v1'\n",
    "MODEL_NAME = 'baby_weight'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bf7827",
   "metadata": {},
   "source": [
    "Now we're ready to create a storage bucket to store our XGBoost model file. We'll point Cloud AI Platform at this file when we deploy.\n",
    "\n",
    "Run this gsutil command from within your notebook to create a bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97ef975a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://coursera-mlops-c4w1l3/...\n"
     ]
    }
   ],
   "source": [
    "!gsutil mb $MODEL_BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869f34b4",
   "metadata": {},
   "source": [
    "#### Step 2: Copy the model file to Cloud Storage\n",
    "\n",
    "Next, we'll copy our XGBoost saved model file to Cloud Storage. Run the following gsutil command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e91ee56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./model.bst [Content-Type=application/octet-stream]...\n",
      "/ [1 files][294.1 KiB/294.1 KiB]                                                \n",
      "Operation completed over 1 objects/294.1 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp ./model.bst $MODEL_BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa8c22d",
   "metadata": {},
   "source": [
    "If you get errors about creating buckets, you may need to enable the Cloud Storage API before retrying the command above. Just search for Cloud Storage using the Search Bar then click Enable API.\n",
    "\n",
    "Head over to the storage browser in your Cloud Console to confirm the file has been copied:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40b7531",
   "metadata": {},
   "source": [
    "#### Step 3: Create and deploy the model\n",
    "\n",
    "The following ai-platform gcloud command will create a new model in your project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "691c6c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
      "Created ai platform model [projects/coursera-mlops-c4w1l3/models/baby_weight].\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform models create $MODEL_NAME --region=us-central1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd55c64",
   "metadata": {},
   "source": [
    "Now it's time to deploy the model. We can do that with this gcloud command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aed49d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
      "Creating version (this might take a few minutes)......done.                    \n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform versions create $VERSION_NAME \\\n",
    "--model=$MODEL_NAME \\\n",
    "--framework='XGBOOST' \\\n",
    "--runtime-version=2.5 \\\n",
    "--origin=$MODEL_BUCKET \\\n",
    "--python-version=3.7 \\\n",
    "--project=$GCP_PROJECT \\\n",
    "--region=us-central1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1447a29",
   "metadata": {},
   "source": [
    "While this is running, check the models section of your AI Platform console. You should see your new version deploying there.\n",
    "When the deploy completes successfully you'll see a green check mark where the loading spinner is. The deployment can take up to 5 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ebc05",
   "metadata": {},
   "source": [
    "#### Step 4: Test the deployed model\n",
    "\n",
    "To make sure your deployed model is working, test it out using gcloud to make a prediction. First, save a JSON file with two examples from our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd98bf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predictions.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile predictions.json\n",
    "[0.0, 33.0, 1.0, 27.0]\n",
    "[1.0, 26.0, 1.0, 40.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddf890d",
   "metadata": {},
   "source": [
    "Test your model by saving the output of the following gcloud command to a variable and printing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49c34fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-ml.googleapis.com/] [2.051780939102173, 7.878574848175049]\n"
     ]
    }
   ],
   "source": [
    "prediction = !gcloud ai-platform predict --model=$MODEL_NAME --json-instances=predictions.json --version=$VERSION_NAME\n",
    "print(prediction.s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f509c7",
   "metadata": {},
   "source": [
    "You should see your model's prediction in the output. The actual baby weight for these two examples is around 2 and 8 pounds respectively (results may differ slightly because we shuffled our dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88607f30",
   "metadata": {},
   "source": [
    "## 8 : Cleanup\n",
    "If you'd like to continue using this notebook, it is recommended that you turn it off when not in use. From the Notebooks UI in your Cloud Console, select the notebook and then select Stop:\n",
    "images/cleanup\n",
    "\n",
    "If you'd like to delete all resources you've created in this lab, simply delete the notebook instance instead of stopping it.\n",
    "\n",
    "Using the Navigation menu in your Cloud Console, browse to Cloud Storage and delete both buckets you created to store your model assets. Similarly, you can also go to the dashboard of AI Platform -> Models to delete the model manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d9c22f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m79"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
